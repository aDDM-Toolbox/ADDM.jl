{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter recovery and computation performance with smaller state step size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `grid_search_benchmarks_outputs.ipynb` we looked at performance of different parallelization schemes (over trials, over parameter combinations and using either Base or Transducers).\n",
    "\n",
    "Regardless of how long they took none of the parallelization combinations recovered the true parameters. Looking at the trialswise posteriors we saw that the posterior for the true model never gained traction.\n",
    "\n",
    "To see if we might be more successful in recovering the true parameters we reduced the \n",
    "\n",
    "Additionally, we also tested the effect of different parallelization schemes to see if there would performance differences in this scenario, where we knew 10x more computations were going to necessary.\n",
    "\n",
    "To download data run:\n",
    "\n",
    "```\n",
    "rsync -av zenkavi@login.hpc.caltech.edu:/central/groups/rnl/zenkavi/ADDM.jl/performance/outputs/ ./performance/outputs/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- \u001b[1mAttaching core tidyverse packages\u001b[22m ------------------------ tidyverse 2.0.0 --\n",
      "\u001b[32mv\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.2     \u001b[32mv\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.4\n",
      "\u001b[32mv\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32mv\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.0\n",
      "\u001b[32mv\u001b[39m \u001b[34mggplot2  \u001b[39m 3.4.2     \u001b[32mv\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32mv\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.2     \u001b[32mv\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.0\n",
      "\u001b[32mv\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
      "-- \u001b[1mConflicts\u001b[22m ------------------------------------------ tidyverse_conflicts() --\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mi\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consisted of 1500 trials generated with parameters d = 0.007, sigma = 0.03, theta = 0.6. The parameter space consisted of 8000 combinations (20 per parameter) where d was sampled between .001 and .020 with a step size of .001, sigma was sampled between .01 and .20 with a step size of .01 and theta was sampled between .27 and .85 with a step size of .03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'../outputs/'"
      ],
      "text/latex": [
       "'../outputs/'"
      ],
      "text/markdown": [
       "'../outputs/'"
      ],
      "text/plain": [
       "[1] \"../outputs/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files_path = \"../outputs/\"\n",
    "files_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'small_stepsize_seq_2024-04-03T00:59:30.668_best_pars.csv'</li><li>'small_stepsize_thread_2024-04-02T19:37:22.786_best_pars.csv'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'small\\_stepsize\\_seq\\_2024-04-03T00:59:30.668\\_best\\_pars.csv'\n",
       "\\item 'small\\_stepsize\\_thread\\_2024-04-02T19:37:22.786\\_best\\_pars.csv'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'small_stepsize_seq_2024-04-03T00:59:30.668_best_pars.csv'\n",
       "2. 'small_stepsize_thread_2024-04-02T19:37:22.786_best_pars.csv'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"small_stepsize_seq_2024-04-03T00:59:30.668_best_pars.csv\"   \n",
       "[2] \"small_stepsize_thread_2024-04-02T19:37:22.786_best_pars.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_files = list.files(files_path, pattern = \"small_stepsize.*best_pars.csv\")\n",
    "param_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'small'</li><li>'stepsize'</li><li>'seq'</li><li>'2024-04-03T00:59:30.668'</li><li>'best'</li><li>'pars.csv'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'small'\n",
       "\\item 'stepsize'\n",
       "\\item 'seq'\n",
       "\\item '2024-04-03T00:59:30.668'\n",
       "\\item 'best'\n",
       "\\item 'pars.csv'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'small'\n",
       "2. 'stepsize'\n",
       "3. 'seq'\n",
       "4. '2024-04-03T00:59:30.668'\n",
       "5. 'best'\n",
       "6. 'pars.csv'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"small\"                   \"stepsize\"               \n",
       "[3] \"seq\"                     \"2024-04-03T00:59:30.668\"\n",
       "[5] \"best\"                    \"pars.csv\"               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fn = param_files[1]\n",
    "strsplit(fn, \"_\")[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "best_pars = tibble()\n",
    "for (fn in param_files) {\n",
    "  cur_pars = read.csv(paste0(files_path, fn))\n",
    "  if(!(\"likelihood_fn\" %in% names(cur_pars))){\n",
    "    cur_pars$likelihood_fn = \"ADDM.aDDM_get_trial_likelihood\"\n",
    "  }\n",
    "  cur_pars = cur_pars %>% select(barrier,bias,d,decay,likelihood_fn,nonDecisionTime,sigma,theta)\n",
    "  fn_info = strsplit(fn, \"_\")[[1]]\n",
    "  cur_pars$grid_fn = \"floop\"\n",
    "  cur_pars$grid_exec = fn_info[3]\n",
    "  cur_pars$trials_exec = \"thread\"\n",
    "  best_pars = bind_rows(best_pars, cur_pars)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both versions recover the correct d and theta and are one step off the theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 2 x 11</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>barrier</th><th scope=col>bias</th><th scope=col>d</th><th scope=col>decay</th><th scope=col>likelihood_fn</th><th scope=col>nonDecisionTime</th><th scope=col>sigma</th><th scope=col>theta</th><th scope=col>grid_fn</th><th scope=col>grid_exec</th><th scope=col>trials_exec</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>0</td><td>0.007</td><td>0</td><td>ADDM.aDDM_get_trial_likelihood</td><td>100</td><td>0.03</td><td>0.63</td><td>floop</td><td>seq   </td><td>thread</td></tr>\n",
       "\t<tr><td>1</td><td>0</td><td>0.007</td><td>0</td><td>ADDM.aDDM_get_trial_likelihood</td><td>100</td><td>0.03</td><td>0.63</td><td>floop</td><td>thread</td><td>thread</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2 x 11\n",
       "\\begin{tabular}{lllllllllll}\n",
       " barrier & bias & d & decay & likelihood\\_fn & nonDecisionTime & sigma & theta & grid\\_fn & grid\\_exec & trials\\_exec\\\\\n",
       " <int> & <dbl> & <dbl> & <int> & <chr> & <int> & <dbl> & <dbl> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t 1 & 0 & 0.007 & 0 & ADDM.aDDM\\_get\\_trial\\_likelihood & 100 & 0.03 & 0.63 & floop & seq    & thread\\\\\n",
       "\t 1 & 0 & 0.007 & 0 & ADDM.aDDM\\_get\\_trial\\_likelihood & 100 & 0.03 & 0.63 & floop & thread & thread\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2 x 11\n",
       "\n",
       "| barrier &lt;int&gt; | bias &lt;dbl&gt; | d &lt;dbl&gt; | decay &lt;int&gt; | likelihood_fn &lt;chr&gt; | nonDecisionTime &lt;int&gt; | sigma &lt;dbl&gt; | theta &lt;dbl&gt; | grid_fn &lt;chr&gt; | grid_exec &lt;chr&gt; | trials_exec &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 0 | 0.007 | 0 | ADDM.aDDM_get_trial_likelihood | 100 | 0.03 | 0.63 | floop | seq    | thread |\n",
       "| 1 | 0 | 0.007 | 0 | ADDM.aDDM_get_trial_likelihood | 100 | 0.03 | 0.63 | floop | thread | thread |\n",
       "\n"
      ],
      "text/plain": [
       "  barrier bias d     decay likelihood_fn                  nonDecisionTime sigma\n",
       "1 1       0    0.007 0     ADDM.aDDM_get_trial_likelihood 100             0.03 \n",
       "2 1       0    0.007 0     ADDM.aDDM_get_trial_likelihood 100             0.03 \n",
       "  theta grid_fn grid_exec trials_exec\n",
       "1 0.63  floop   seq       thread     \n",
       "2 0.63  floop   thread    thread     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried two parallelizations schemes: 1. Parallelize over both trials and parameter combinations. Parallelization over parameter combinations was done using ThreadedEx() in FLoops.jl, part of the Transducers.jl ecosystem. Parallelization over trials used Based.threads. 2. Parallelize over trials only. This used the same functions as the first but with SequentialEx() in the grid_search function.  \n",
    "\n",
    "Previous results showed no gains in computation time when parallelizing over both trials and parameter combinations, which suggested that using Transducers was not setting up a hierarchical structure across threads. It also implied that giving the same resources to either setup should yield comparable comparable computation times, provided that all threads are utilized efficiently.  \n",
    "\n",
    "Hypothetically, two aspects of the data would affect computation times:  \n",
    "- How many likelihood computations? RT/time step for each trial x 8000 - should affect computation time  \n",
    "- How many things to computate for each timestep boundary*2/state step - should affect memory (more)  \n",
    "\n",
    "Despite previous results, we find that parallelizing over both the trials and parameter combinations was about 5.5 hours faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does memory usage change with decrease state step size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
