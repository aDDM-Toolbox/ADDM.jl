var documenterSearchIndex = {"docs":
[{"location":"tutorials/05_custom_model/#Defining-custom-models","page":"Defining custom models","title":"Defining custom models","text":"","category":"section"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"Though the packages comes with the standard attentional DDM that allows for multiplicative and additive discounting of unattended items, users might also conceive of other generative processes (within the sequantial sampling to a bound framework) that give rise to observed choices and response times.  ","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"In this tutorial we lay out the framework for how to incorporate such models within our toolbox to take advantage of Julia's processing speed.  ","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"Broadly, this involves defining three parts: ","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"trial simulator describing how the new parameter changes the data generating process resulting in a choice and response time\nthis is then fed into ADDM.simulate_data along with the model object and stimuli to generate choice and response times.\nmodel object with new parameter\nthis is only a container of key-value pairs of parameter names and values used a convenient wrapper to feed into the simulator and likelihood computer.\ntrial likelihood function computing the probability of the observed choice and response time\nthis is then fed into ADDM.grid_search along with the data you want to compute the likelihoods for and the parameter search space.","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"Let's begin with importing the packages we'll use in this tutorial.","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"using ADDM, CSV, DataFrames, DataFramesMeta, Distributions, LinearAlgebra, StatsPlots","category":"page"},{"location":"tutorials/05_custom_model/#Define-simulator","page":"Defining custom models","title":"Define simulator","text":"","category":"section"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"The built-in model has a decay parameter for a linear decay of the barrier. Let's build a model with an exponential decay of the barrier such that the barrier at each timestep is defined as barrier(t) = exp(-λt).","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"Based on the built-in trial simulators as defined here the trial simulator would look like this. The custom model trial simulator is identical to the built-in simulators except for where the barriers for the accummulation process is defined:","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"include(\"my_trial_simulator.jl\"); nothing # hide","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"function my_trial_simulator(;model::ADDM.aDDM, fixationData::ADDM.FixationData, \n                        valueLeft::Number, valueRight::Number, \n                        timeStep::Number=10.0, numFixDists::Int64=3, cutOff::Number=100000)\n    \n   [...]\n\n    # The values of the barriers can change over time.\n    # In this case we include an exponential decay\n    # Due to the shape of the exponential decay function the starting point for the decay is exp(0) = 1\n    barrierUp = exp.(-model.λ .* (0:cutOff-1))\n    barrierDown = -exp.(-model.λ .* (0:cutOff-1))\n    \n    [...]\n\n    trial = ADDM.Trial(choice = choice, RT = RT, valueLeft = valueLeft, valueRight = valueRight)\n    trial.fixItem = fixItem \n    trial.fixTime = fixTime \n    trial.fixRDV = fixRDV\n    trial.uninterruptedLastFixTime = uninterruptedLastFixTime\n    trial.RDV = tRDV\n    return trial\nend","category":"page"},{"location":"tutorials/05_custom_model/#Define-model-container","page":"Defining custom models","title":"Define model container","text":"","category":"section"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"Then we create a model object of class aDDM to store the parameters of our model. There are two ways of doing this. First, we could use the ADDM.define_model function. That would like:","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"my_model = ADDM.define_model(d = 0.007, σ = 0.03, θ = .6, barrier = 1, nonDecisionTime = 100, bias = 0.0)","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"my_model.λ = .05;","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"The ADDM.define_model function is limited to the standard parameter names. So the new parameter λ is added to the model after its creation. Alternatively, we can create an empty model object and add our parameters individually.","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"my_model = ADDM.aDDM()\nmy_model.d = 0.007\nmy_model.σ = 0.03\nmy_model.θ = .6\nmy_model.η = 0\nmy_model.barrier = 1\nmy_model.nonDecisionTime = 100\nmy_model.bias = 0.0\nmy_model.λ = .05","category":"page"},{"location":"tutorials/05_custom_model/#Simulate-data","page":"Defining custom models","title":"Simulate data","text":"","category":"section"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"Now that we have defined the generative process (the simulator function) and the model (the parameter values) there are two more necessary inputs for simulating data: stimuli (pairs of values for different objects) and fixation data (location and duration).","category":"page"},{"location":"tutorials/05_custom_model/#Define-stimuli-and-fixation-distribution","page":"Defining custom models","title":"Define stimuli and fixation distribution","text":"","category":"section"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"We will use data from Tavares et al. (2017) that comes with the toolbox. Importantly, we will only be using the stimuli and fixations from this dataset, not the empirical choice and response times. This is ensured by the stimsOnly argument of the ADDM.load_data_from_csv function. By using the stimuli and the fixations to sample from, we will generate choice and response using our custom simulator function. ","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"data = ADDM.load_data_from_csv(\"../../../data/stimdata.csv\", \"../../../data/fixations.csv\"; stimsOnly = true);","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"Extract stimulus values from this dataset and wrangle into the format expected by the simulator function.","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"nTrials = 2400;\nmy_stims = (valueLeft = reduce(vcat, [[i.valueLeft for i in data[j]] for j in keys(data)])[1:nTrials], valueRight = reduce(vcat, [[i.valueRight for i in data[j]] for j in keys(data)])[1:nTrials]);","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"Aggregate fixations from all subjects to create fixation duration distributions indexed by value difference and order (1st, 2nd etc.). Since the fixations will be indexed by the value difference, this is extracted from the stimuli and used as an input to the ADDM.process_fixations function. The simulator function will sample from this aggregate data.","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"vDiffs = sort(unique(reduce(vcat, [[i.valueLeft - i.valueRight for i in data[j]] for j in keys(data)])));\n\nmy_fixations = ADDM.process_fixations(data, fixDistType=\"fixation\", valueDiffs = vDiffs);","category":"page"},{"location":"tutorials/05_custom_model/#Simulate-choice-and-response-times","page":"Defining custom models","title":"Simulate choice and response times","text":"","category":"section"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"Now that we have read in each of the required inputs we can simulate data with our custom simulator function. To do so we specify the third positional argument to the wrapper function ADDM.simulate_data as my_trial_simulator so it knows to use this function to generate choice and response times.","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"my_args = (timeStep = 10.0, cutOff = 20000, fixationData = my_fixations);\n\nmy_sim_data = ADDM.simulate_data(my_model, my_stims, my_trial_simulator, my_args);","category":"page"},{"location":"tutorials/05_custom_model/#Define-likelihood-function","page":"Defining custom models","title":"Define likelihood function","text":"","category":"section"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"Based on the built-in likelihood function as defined here the custom likelihood function would look like this. The custom likelihood function is identical to the built-in function except for where the barriers for the accummulation process is defined:","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"include(\"my_likelihood_fn.jl\"); nothing # hide","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"function my_likelihood_fn(;model::ADDM.aDDM, trial::ADDM.Trial, timeStep::Number = 10.0, \n                                   stateStep::Number = 0.1)\n    \n    [...]\n\n    # The values of the barriers can change over time.\n    barrierUp = exp.(-model.λ .* (0:numTimeSteps-1))\n    barrierDown = -exp.(-model.λ .* (0:numTimeSteps-1))\n    \n    [...]\n    \n    # Compute the likelihood contribution of this trial based on the final\n    # choice.\n    likelihood = 0\n    if trial.choice == -1 # Choice was left.\n        if probUpCrossing[end] > 0\n            likelihood = probUpCrossing[end]\n        end\n    elseif trial.choice == 1 # Choice was right.\n        if probDownCrossing[end] > 0 \n            likelihood = probDownCrossing[end]\n        end\n    end\n    \n    return likelihood\nend","category":"page"},{"location":"tutorials/05_custom_model/#Recover-parameters-for-simulated-data","page":"Defining custom models","title":"Recover parameters for simulated data","text":"","category":"section"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"Now that we have generated some data using known parameters with our custom simulator and defined the likelihood function to compute the likelihood of a choice and response time pair associated with a specific fixation pattern, we can compute the likelihoods for a range of parameter combinations to confirm that the likelihood function correctly recovers the true parameters.","category":"page"},{"location":"tutorials/05_custom_model/#Define-search-grid","page":"Defining custom models","title":"Define search grid","text":"","category":"section"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"fn = \"../../../data/custom_model_grid.csv\";\ntmp = DataFrame(CSV.File(fn, delim=\",\"));\nparam_grid = NamedTuple.(eachrow(tmp));","category":"page"},{"location":"tutorials/05_custom_model/#Run-grid-search-on-simulated-data","page":"Defining custom models","title":"Run grid search on simulated data","text":"","category":"section"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"fixed_params = Dict(:η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>100, :bias=>0.0);\n\nmy_likelihood_args = (timeStep = 10.0, stateStep = 0.1);\n\noutput = ADDM.grid_search(my_sim_data, param_grid, my_likelihood_fn,\n    fixed_params, \n    likelihood_args=my_likelihood_args, \n    return_grid_nlls = true, return_trial_posteriors = true, return_model_posteriors = true);\n\nbest_pars = output[:best_pars];\nnll_df = output[:grid_nlls];\ntrial_posteriors = output[:trial_posteriors];\nmodel_posteriors = output[:model_posteriors];","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"The true parameters are d = 0.007, σ = 0.03, θ = .6, λ = .05. Even with smaller state space step size the correct decay is not recovered. Instead, the fast response times are attributed to faster drift rates and larger sigmas.","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"sort!(nll_df, [:nll]);\n\nshow(nll_df, allrows = true)","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"The posteriors have no uncertainty either.","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"marginal_posteriors = ADDM.marginal_posteriors(param_grid, model_posteriors, true);\n\nADDM.margpostplot(marginal_posteriors)\n\nsavefig(\"plot_4_1.png\"); nothing # hide","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"(Image: plot)","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"How do the posteriors change across trials?","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"trial_param_posteriors = DataFrame();\n\nfor i in 1:nTrials\n\n  # Get the posterior for each model after the curent trial\n  cur_trial_posteriors = Dict(zip(keys(trial_posteriors), [x[i] for x in values(trial_posteriors)]))\n\n  # Use built-in function to marginalize for each parameter\n  cur_param_posteriors = ADDM.marginal_posteriors(param_grid, cur_trial_posteriors)\n\n  # Wrangle the output to be a single df and add trial number info\n  for j in 1:length(cur_param_posteriors)\n    df = cur_param_posteriors[j][:,:] #assign a copy\n    \n    df[!, :par_name] .= names(df)[1]\n    df[!, :trial_num] .= i\n    rename!(df, Symbol(names(df)[1]) => :par_value)\n\n    trial_param_posteriors = vcat(trial_param_posteriors, df, cols=:union)\n\n  end\n\nend;\n\npar_names = unique(trial_param_posteriors[:,:par_name]);\n\nplot_array = Any[];\n\nfor cur_par_name in par_names\n\n  plot_df = @rsubset(trial_param_posteriors, :par_name == cur_par_name)\n\n  cur_plot = @df plot_df plot(\n      :trial_num,\n      :posterior_sum,\n      group = :par_value,\n      title = cur_par_name,\n      xlabel = \"Trial\",\n      ylabel = \"Posterior p\",\n  )\n\n  push!(plot_array, cur_plot)\n\nend;\n\nplot(plot_array...)\n\nsavefig(\"plot_4_2.png\"); nothing # hide","category":"page"},{"location":"tutorials/05_custom_model/","page":"Defining custom models","title":"Defining custom models","text":"(Image: plot)","category":"page"},{"location":"tutorials/07_alt_optimization_algs/","page":"-","title":"-","text":"Summary of how Wenning implements optim with a likelihood function","category":"page"},{"location":"tutorials/07_alt_optimization_algs/","page":"-","title":"-","text":"","category":"page"},{"location":"tutorials/04_model_comparison/#Model-comparison","page":"Model comparison","title":"Model comparison","text":"","category":"section"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"The parameter combination that has the highest likelihood to have generated a given dataset (the maximum likelihood estimate) is often what is used in downstream analyses and related to other variables of interest. While a fast estimation these parameters is therefore very useful, it is valueable to get a sense of the uncertainty associated with the estimation as well. In this tutorial we introduce some of the toolbox's capabilities to assess this.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"When estimating the best-fitting parameters for a model (aDDM or otherwise) our ability to recover them is always limited to the parameter space we explore. Therefore, any computation of the uncertainty associated with specific parameters values is only with respect to other values that we have tried.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"In other words, the uncertainty is not some divine measure that accounts for all possible models. It is a comparative measure that tells us how much better a specific combination of parameters is, compared to other combinations in the parameter space we have defined. In this toolbox, we make the parameter space explicit by specifying the grid (param_grid) in the ADDM.grid_search function. ","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"The uncertainty associated with each parameter value and/or parameter combination is quantified as a probability distribution. Specifically, a posterior probability distribution that reflects both the prior beliefs on how likely each parameter value is and how much to update them based on the evidence each trial provides in favor of a parameter combination.","category":"page"},{"location":"tutorials/04_model_comparison/#Comparing-parameters-of-a-single-generative-processes","page":"Model comparison","title":"Comparing parameters of a single generative processes","text":"","category":"section"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"In this section we will demonstrate how to compute posterior probabilities associated with each parameter combination and each parameter type for a single generative process. A generative process, in this context, refers to the computational model we believe gives rise to observable data (in this case, choices and response times). Here, we compute the uncertainty over different parameter combinations of one specific computational model, the standard aDDM. In the next section we compute the uncertainty over different computational models, accounting for the uncertainty within the parameter spaces of each model.","category":"page"},{"location":"tutorials/04_model_comparison/#Posterior-model-probability","page":"Model comparison","title":"Posterior model probability","text":"","category":"section"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"We begin with importing the packages that will be used in this tutorial.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"using ADDM, CSV, DataFrames, DataFramesMeta, Distributed, Distributions, LinearAlgebra, StatsPlots","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"The toolbox comes with a subset of the data from Krajbich et al. (2010). In this tutorials we will use data from a single subject from this dataset.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"data_path = \"../../../data/\"; # hide\nkrajbich_data = ADDM.load_data_from_csv(data_path * \"Krajbich2010_behavior.csv\", data_path * \"Krajbich2010_fixations.csv\");\n\nsubj_data = krajbich_data[\"18\"];","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"To examine the uncertainty associated with each parameter and their combinations we introduce the return_model_posteriors argument when running ADDM.grid_search, which expands the output to include a trial_posteriors dictionary. trial_posteriors is indexed by the keys of param_grid as indicators of different parameter combinations and contains the posterior probability for each key after each trial as its values.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"fn = data_path * \"Krajbich_grid3.csv\";\ntmp = DataFrame(CSV.File(fn, delim=\",\"));\nparam_grid = NamedTuple.(eachrow(tmp));\n\nmy_likelihood_args = (timeStep = 10.0, stateStep = 0.01);\n\noutput = ADDM.grid_search(subj_data, param_grid, ADDM.aDDM_get_trial_likelihood, \n    Dict(:η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>0, :bias=>0.0), \n    likelihood_args=my_likelihood_args, \n    return_grid_nlls = true, return_trial_posteriors = true, return_model_posteriors = true);\n\nmle = output[:mle];\nnll_df = output[:grid_nlls];\ntrial_posteriors = output[:trial_posteriors];\nmodel_posteriors = output[:model_posteriors];","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"note: Note\nmodel_posteriors contains the posterior probability associated with each model (i.e. parameter combination) for the set of models that were fit. Since it is a probability distribution it must sum to 1. In other words, the posterior probabilities associated with the models would change if they were being compared to different combinations of parameters, because they would be renormalized with respect to a different set of likelihoods.","category":"page"},{"location":"tutorials/04_model_comparison/#Model-posteriors","page":"Model comparison","title":"Model posteriors","text":"","category":"section"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"The model_posteriors variable is a dictionary indexed by the parameter combination as listed in the param_grid. Here, we convert that model_posteriors dictionary to a dataframe so it is easier to make plots with.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"posteriors_df1 = DataFrame();\n\nfor (k, v) in model_posteriors\n  cur_row = DataFrame([k])\n  cur_row.posterior = [v]\n  posteriors_df1 = vcat(posteriors_df1, cur_row, cols=:union)\nend;","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Now we can visualize the posterior probability for each parameter combination. ","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"note: Note\nDataFrameMeta.jl provides functionality similar to the R package dplyr (e.g. @chain is similar to a piping operation and @rsubset to select.  ","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Below we're only plotting the posteriors for models that have a meaningful amount of probability mass instead of all the models that were tested by excluding rows without a posterior probability greater than 1e-10.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"plot_df = @chain posteriors_df1 begin\n  @rsubset :posterior > 1e-10\n  @rtransform :x_label = \"d: \" * string(:d) * \", \\nσ: \" * string(:sigma) * \", \\nθ: \" * string(:theta) \n  @orderby -:posterior\n  end;\n\nsort(posteriors_df1, :posterior, rev=true)","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"@df plot_df bar(:x_label, :posterior, legend = false, xrotation = 45, ylabel = \"p(model|data)\",bottom_margin = (5, :mm))\n\nsavefig(\"plot_3_1.png\"); nothing # hide","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"(Image: plot)","category":"page"},{"location":"tutorials/04_model_comparison/#Trialwise-changes-to-the-model-posteriors","page":"Model comparison","title":"Trialwise changes to the model posteriors","text":"","category":"section"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"The ADDM.grid_search function's return_trial_posteriors argument returns the discretized posterior distribution for each model after each trial/observation. This allows us to examine how the posterior distribution changes accounting for increasing amounts of data. The trial_posteriors key of the grid_search output is organized as a dictionary with keys indicating parameter combinations from param_grid and values are nested dictionaries mapping trial numbers to posterior probabilities.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"To do so, first we rangle the trial_posteriors into a data frame for easier visualization.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"# Initialize empty df\ntrial_posteriors_df = DataFrame();\nnTrials = length(subj_data)\n\nfor i in 1:nTrials\n\n  # Get the posterior for each model after the curent trial\n  cur_trial_posteriors = DataFrame(keys(trial_posteriors))\n  cur_trial_posteriors[!, :posterior] = [x[i] for x in values(trial_posteriors)]\n  \n  # Add the trial information\n  cur_trial_posteriors[!, :trial_num] .= i\n\n  # Add the current trial posterior to the initialized df\n  trial_posteriors_df = vcat(trial_posteriors_df, cur_trial_posteriors, cols=:union)\nend;\n\n@transform!(trial_posteriors_df, @byrow :modelnum = string(:d) * string(:sigma) * string(:theta))","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Then, plot changes to posteriors of each model across trials. Note, we have omitted a legend indicating the parameters associated with each line in the plot below to avoid over-crowding the plot. This is meant only as an intial exploration into how the conclusions about the best model vary with increased evidence from each trial.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"@df trial_posteriors_df plot(\n      :trial_num,\n      :posterior,\n      group = :modelnum,\n      xlabel = \"Trial\",\n      ylabel = \"Posterior p\",\n      legend = false\n  )\n\nsavefig(\"plot_3_2.png\"); nothing # hide","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"(Image: plot)","category":"page"},{"location":"tutorials/04_model_comparison/#Parameter-posteriors","page":"Model comparison","title":"Parameter posteriors","text":"","category":"section"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"The model_posteriors dictionary contains the probability distribution associated with each parameter combination. The ADDM.marginal_posteriors function summarizes this by collapsing over levels of different parameters. Below, we first summarize the distribution for each of the three parameters separately.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"param_posteriors = ADDM.marginal_posteriors(model_posteriors);\n\nplot_array = Any[];\nfor plot_df in param_posteriors\n  x_lab = names(plot_df)[1]\n  cur_plot = @df plot_df bar(plot_df[:, x_lab], :posterior_sum, leg = false, ylabel = \"p(\" * x_lab * \" = x|data)\", xlabel = x_lab )\n  push!(plot_array, cur_plot) \nend;\nplot(plot_array...) \n\nsavefig(\"plot_3_3.png\"); nothing # hide","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"(Image: plot)","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"We can also use the ADDM.marginal_posteriors function to compute parameter posteriors with respect to each other by specifying the second positional argument. When set to true, the ADDM.marginal_posteriors function returns pairwise marginal distributions that can be plotted as heatmaps to visualize conditional distributions of the parameters.   ","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"all_marginal_posteriors = ADDM.marginal_posteriors(model_posteriors, two_d_marginals = true)","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"The toolbox includes a visualization function, ADDM.marginal_posterior_plot that creates a grid of plots with individual parameter posteriors on the diagonal and the conditional posteriors as heatmaps below the diagonal.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"ADDM.marginal_posterior_plot(all_marginal_posteriors)\n\nsavefig(\"plot_3_4.png\"); nothing # hide","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"(Image: plot)","category":"page"},{"location":"tutorials/04_model_comparison/#Trialwise-changes-to-the-parameter-posteriors","page":"Model comparison","title":"Trialwise changes to the parameter posteriors","text":"","category":"section"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Similar to trialwise changes for combinations of parameters, we can also examine trialwise changes to marginalized posteriors for each individual parameter as well. Here we do so by using ADDM.marginal_posteriors for each entry in trial_posteriors.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"# Initialize empty df\ntrial_param_posteriors = DataFrame();\n\nfor i in 1:nTrials\n\n  # Get the posterior for each model after the curent trial\n  cur_trial_posteriors = Dict(zip(keys(trial_posteriors), [x[i] for x in values(trial_posteriors)]))\n\n  # Use built-in function to marginalize for each parameter\n  cur_param_posteriors = ADDM.marginal_posteriors(cur_trial_posteriors)\n\n  # Wrangle the output to be a single df and add trial number info\n  for j in 1:length(cur_param_posteriors)\n    df = cur_param_posteriors[j][:,:] #assign a copy\n    \n    df[!, :par_name] .= names(df)[1]\n    df[!, :trial_num] .= i\n    rename!(df, Symbol(names(df)[1]) => :par_value)\n\n    trial_param_posteriors = vcat(trial_param_posteriors, df, cols=:union)\n\n  end\n\nend","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Plot trialwise marginal posteriors for each parameter","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"par_names = unique(trial_param_posteriors[:,:par_name]);\n\nplot_array = Any[];\n\nfor cur_par_name in par_names\n\n  plot_df = @rsubset(trial_param_posteriors, :par_name == cur_par_name)\n\n  cur_plot = @df plot_df plot(\n      :trial_num,\n      :posterior_sum,\n      group = :par_value,\n      title = cur_par_name,\n      xlabel = \"Trial\",\n      ylabel = \"Posterior p\",\n  )\n\n  push!(plot_array, cur_plot)\n\nend\n\nplot(plot_array...)\n\nsavefig(\"plot_3_5.png\"); nothing # hide","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"(Image: plot)","category":"page"},{"location":"tutorials/04_model_comparison/#Comparing-different-generative-processes","page":"Model comparison","title":"Comparing different generative processes","text":"","category":"section"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Aside from comparing different parameter combinations for a single model, we can also compare how likely one computational model is compared to another, in generating the observed data. Since any specific value of a given parameter involves uncertainty as we computed above, we need to account for this when comparing different generative processes to each other.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"This again involves computing the comparative advantage, the posterior probability, for each point in the parameter space that we examine, which contains both the parameters within each model, and which model they belong to. ","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Here, we'll use the same participant's data from before and examine if it can be explained better by a standard aDDM (that we fit above) or another model where the boundaries of the evidence accummulation decay exponentially throughout the decision. This model is detailed further in the Defining custom models tutorial.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"The comparison of these two generative processes is operationalized by specifying them in the same param_grid as we had previously used to specify different values for the parameters of a single generative process. In this case, we add the information on which generative process the parameter combination belongs to in a new key called likelihood_fn.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"First we read in the file that defines the parameter space for the first model, the standard aDDM.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"fn1 = data_path * \"Krajbich_grid3.csv\";\ntmp = DataFrame(CSV.File(fn1, delim=\",\"));\ntmp.likelihood_fn .= \"ADDM.aDDM_get_trial_likelihood\";\nparam_grid1 = NamedTuple.(eachrow(tmp));","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Then we define the likelihood function for the second model. We do this by reading in a custom function we have defined in a separate script. This script includes a function called my_likelihood_fn. We will use this function name string when defining the parameter space.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"note: Note\n@everywhere is a macro defined by Distributed.jl. It ensures that the likelihood function is available to all processes when parallelizing computations.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"@everywhere include(\"./my_likelihood_fn.jl\");\nfn_module = [meth.module for meth in methods(my_likelihood_fn)][1]; # hide","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Now we define the parameter space we will examine for the second model. In addition to the parameter values we also include my_likelihood_fn as a string in param_grid so ADDM.grid_search knows which generative process to use when computing the trial likelihoods for the parameter combinations of the second model. ","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"fn2 = data_path * \"custom_model_grid.csv\";\ntmp = DataFrame(CSV.File(fn2, delim=\",\"));\ntmp.likelihood_fn .= \"my_likelihood_fn\";\nparam_grid2 = NamedTuple.(eachrow(tmp));","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Now that we have defined the parameter space for both models, we combine them both in a single param_grid, over which we'll compute the posterior distribution.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"param_grid = vcat(param_grid1, param_grid2)","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"With this expanded param_grid that includes information on the different likelihood functions we call the ADDM.grid_search function setting the third position argument to nothing. This argument is where we define the likelihood function in the case of a single model but now this is specified in the param_grid.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"my_likelihood_args = (timeStep = 10.0, stateStep = 0.01);\n  \noutput = ADDM.grid_search(subj_data, param_grid, nothing,\n    Dict(:η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>0, :bias=>0.0), \n    likelihood_args = my_likelihood_args, \n    return_grid_nlls = true, return_trial_posteriors = true, return_model_posteriors = true);\n\nmle = output[:mle]\nnll_df = output[:grid_nlls]\ntrial_posteriors = output[:trial_posteriors];\nmodel_posteriors = output[:model_posteriors];","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"As before, we create a dataframe containing the model_posteriors for visualization purposes.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"posteriors_df2 = DataFrame();\n\nfor (k, v) in model_posteriors\n  cur_row = DataFrame([k])\n  cur_row.posterior = [v]\n  posteriors_df2 = vcat(posteriors_df2, cur_row, cols=:union)\nend;","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"We can take a look at the most likely parameter combinations across the generative processes.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"sort(posteriors_df2, :posterior, rev=true)","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"note: Note\nThe posterior probability associated with the standard model for parameters d = 0.00085, sigma = 0.055  and theta =  0.5  is not the same as what it was when comparing the parameter combinations for a single generative process in the first section of this tutorial. Now, this posterior is normalized not only over the parameter combinations of the standard model but also over all the combinations that we examined for the alternative model.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"sort(posteriors_df1, :posterior, rev=true)[1,:posterior] == sort(posteriors_df2, :posterior, rev=true)[1,:posterior]","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"We can also collapse the posterior distribution across the generative processes and compare how much better one processes is compared to the other in giving rise to the observed data.  ","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"gdf = groupby(posteriors_df2, :likelihood_fn);\ncombdf = combine(gdf, :posterior => sum);\n\n@df combdf bar(:likelihood_fn, :posterior_sum, legend = false, xrotation = 45, ylabel = \"p(model|data)\",bottom_margin = (5, :mm))\n\nsavefig(\"plot_3_6.png\"); nothing # hide","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"(Image: plot)","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"We can check how this conclusion evolved with the addition of each trial.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"# Initialize empty df\ntrial_model_posteriors = DataFrame();\n\nfor i in 1:nTrials\n\n  # Get the posterior for each model after the curent trial\n  cur_trial_posteriors = Dict(zip(keys(trial_posteriors), [x[i] for x in values(trial_posteriors)]))\n\n  cur_trial_posteriors = DataFrame(model_num = collect(keys(cur_trial_posteriors)), posterior = collect(values(cur_trial_posteriors)))\n\n  @transform!(cur_trial_posteriors, @byrow :likelihood_fn = :model_num.likelihood_fn)\n\n  gdf = groupby(cur_trial_posteriors, :likelihood_fn)\n  cur_trial_posteriors = combine(gdf, :posterior => sum)\n\n  # Add the trial information\n  cur_trial_posteriors[!, :trial_num] .= i\n\n  # Add the current trial posterior to the initialized df\n  trial_model_posteriors = vcat(trial_model_posteriors, cur_trial_posteriors, cols=:union)\nend;\n\n@df trial_model_posteriors plot(\n      :trial_num,\n      :posterior_sum,\n      group = :likelihood_fn,\n      xlabel = \"Trial\",\n      ylabel = \"Posterior p\",\n      legend = true\n  )\n\nsavefig(\"plot_3_7.png\"); nothing # hide","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"(Image: plot)","category":"page"},{"location":"tutorials/04_model_comparison/#Priors-about-models","page":"Model comparison","title":"Priors about models","text":"","category":"section"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Suppose we had very strong prior beliefs about two of the models in our parameter space. We specify this belief as a probability of .495 for two models and assign the remaining probability mass to all other models.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Important: ","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Make sure the keys of the model priors dictionary has the same keys for all models (ADDM.match_param_grid_keys).\nMake sure there is some probability mass for all models (i.e. all values in model priors dictionary should be larger than 0.).\nMake sure that the values of model priors sum up to 1 (i.e. so it a proper probability distribution).","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"This is not a good example to demonstrate the effect of priors because the evidence against the custom model is too strong immediately after the first trial.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"param_grid = ADDM.match_param_grid_keys(param_grid)\nn_models = length(param_grid)\n\nmy_priors = Dict(zip(param_grid, repeat([(1-(.495*2))/(n_models)], outer = n_models)))\nmy_priors[(d = 0.014, sigma = 0.07, theta = 0.9, lambda = 0.01, likelihood_fn = \"my_likelihood_fn\")] = .495\nmy_priors[(d = 0.014, sigma = 0.07, theta = 0.6, lambda = 0.01, likelihood_fn = \"my_likelihood_fn\")] = .495\n\noutput = ADDM.grid_search(subj_data, param_grid, nothing,\n    Dict(:η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>0, :bias=>0.0), \n    likelihood_args = my_likelihood_args, \n    model_priors = my_priors,\n    return_grid_nlls = true, return_trial_posteriors = true, return_model_posteriors = true);\n\nmle = output[:mle]\nnll_df = output[:grid_nlls]\ntrial_posteriors = output[:trial_posteriors];\nmodel_posteriors = output[:model_posteriors];","category":"page"},{"location":"tutorials/04_model_comparison/#Comparing-true-data-with-simulated-data","page":"Model comparison","title":"Comparing true data with simulated data","text":"","category":"section"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"The comparison of the generative processes above strongly favors the standard aDDM over the custom model in generating the observed data (within the ranges of the parameter space we explored).","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Another way to examine how well a model describes observed data is by comparing how well it predicts observed patterns. In this case, this would involve inspecting response time distributions conditional on choice, as these are the two outputs of the generative models.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"One can choose different features and statistics about the observed data to compare with model predictions. Below, we plot how the response time distributions for the best fitting model from each generative process compares to the true data.  ","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"First, we get best fitting parameters for each model.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"bestModelPars = @chain posteriors_df2 begin\n    groupby(:likelihood_fn) \n    combine(_) do sdf\n        sdf[argmax(sdf.posterior), :]\n    end\n  end;","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Using these parameters for each model we simulate data for the stimuli used in the true data.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"We begin with preparing the inputs for the simulating function. These are the fixation data, simulator arguments and the stimuli.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"vDiffs = sort(unique([x.valueLeft - x.valueRight for x in subj_data]));\nfixData = ADDM.process_fixations(krajbich_data, fixDistType=\"fixation\", valueDiffs = vDiffs);\n\nMyArgs = (timeStep = 10.0, cutOff = 20000, fixationData = fixData);\n\nMyStims = (valueLeft = [x.valueLeft for x in subj_data], valueRight = [x.valueRight for x in subj_data])","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Then, we define the standard model with the best fitting parameters.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"standPars = @rsubset bestModelPars :likelihood_fn == \"ADDM.aDDM_get_trial_likelihood\";\n\nstandModel = ADDM.define_model(d = standPars.d[1], σ = standPars.sigma[1], θ = standPars.theta[1]);","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Now that the model and the inputs for the simulator are defined we can simulate data.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"simStand = ADDM.simulate_data(standModel, MyStims, ADDM.aDDM_simulate_trial, MyArgs);","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"We repeat these steps for the alternative model. The simulator function for this model is defined in my_trial_simulator.jl so we need to source that into our session before we can call the function.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"@everywhere include(\"./my_trial_simulator.jl\")","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Now we can define the alternative model with the best fitting parameters for that model and simulate data.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"## Define standard model with the best fitting parameters\naltPars = @rsubset bestModelPars :likelihood_fn == \"my_likelihood_fn\";\naltModel = ADDM.define_model(d = altPars.d[1], σ = altPars.sigma[1], θ = altPars.theta[1])\naltModel.λ = altPars.lambda[1];\n\n## Simulate data for the best alternative model\nsimAlt = ADDM.simulate_data(altModel, MyStims, my_trial_simulator, MyArgs);","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Now that we have simulated data using both generative processes, we can plot the response time data for the true and simulated data. We will visualize this as histograms and kernel density estimates of RT distributions conditional on choice. The RTs for left choices will be on the left side of the plot and vice versa for right choice RTs. For visualization purposes the left choice RTs are multiplied by -1.","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"# Plot true RT histograms overlaid with simulated RT histograms\n\n## Define the limit for the x-axis based on true data\nrts = [i.RT * i.choice for i in subj_data]; #left choice rt's are negative\nl = abs(minimum(rts)) > abs(maximum(rts)) ? abs(minimum(rts)) : abs(maximum(rts))\n\n## Split the RTs for left and right choice. Left is on the left side of the plot\nrts_pos = [i.RT for i in subj_data if i.choice > 0];\nrts_neg = [i.RT * (-1) for i in subj_data if i.choice < 0];\n\nrts_pos_stand = [i.RT for i in simStand if i.choice > 0];\nrts_pos_alt = [i.RT for i in simAlt if i.choice > 0];\n\nrts_neg_stand = [i.RT * (-1) for i in simStand if i.choice < 0];\nrts_neg_alt = [i.RT * (-1) for i in simAlt if i.choice < 0];","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"Having extracted the data for both the true and simulated RTs we can plot them on top each other. ","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"## Make plot\n\nhistogram(rts_pos, normalize=true, bins = range(-l, l, length=41), fillcolor = \"gray\", yaxis = false, grid = false, label = \"True data\")\ndensity!(rts_pos_stand, label = \"ADDM predictions\", linewidth = 3, linecolor = \"blue\")\ndensity!(rts_pos_alt, label = \"Custom model predictions\", linewidth = 3, linecolor = \"green\")\n\nhistogram!(rts_neg, normalize=true, bins = range(-l, l, length=41), fillcolor = \"gray\", label = \"\")\ndensity!(rts_neg_stand, linewidth = 3, linecolor = \"blue\", label = \"\")\ndensity!(rts_neg_alt, linewidth = 3, linecolor = \"green\", label = \"\")\n\nvline!([0], linecolor = \"red\", label = \"\")\n\nsavefig(\"plot_3_8.png\"); nothing # hide","category":"page"},{"location":"tutorials/04_model_comparison/","page":"Model comparison","title":"Model comparison","text":"(Image: plot)","category":"page"},{"location":"tutorials/03_empirical_data/#Parameter-estimation-on-empirical-data","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"","category":"section"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"Previously, we recovered known parameters on simulated data. But often, we do not know these parameters and instead work with empirical data. In this tutorial we will walk through how to organize empirical data to use the toolbox functions.","category":"page"},{"location":"tutorials/03_empirical_data/#Load-packages","page":"Parameter estimation on empirical data","title":"Load packages","text":"","category":"section"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"We begin with loading the modules for the tutorial.","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"using ADDM, CSV, DataFrames, StatsPlots","category":"page"},{"location":"tutorials/03_empirical_data/#Read-in-data","page":"Parameter estimation on empirical data","title":"Read in data","text":"","category":"section"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"Data in this tutorial are from 10 subjects in Kraijbich et al (2010). We will use the built-in data loading function ADDM.load_data_from_csv that expects a behavioral file with columns parcode, trial, rt, choice, item_left, item_right and fixations file with columns parcode, trial, fix_item, fix_time.","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"If your data is not organized in this way you could either preprocess it so it does or you can read in the data however you want and reshape it with Julia to ensure it is organized as a dictionary of Trial objects indexed by subject/parcode. A Trial looks like","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"ADDM.Trial(1, 1474.0, -5, 5, Number[3, 0, 1, 0, 2, 0], Number[270.0, 42.0, 246.0, 62.0, 558.0, 296.0], #undef, #undef, #undef)","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"where the first element is choice (-1 for left, +1 for right), second element is response time in ms, third is value of left option, fourth is value of right option. Fixation data is specified in the fourth and fifth elements as fixation location (1 for left, 2 for right) and fixation duration (in ms) respectively. The remaning elements currently set to #undef can be ignored. These are for debugging/examining the relative decision value when simulating trials.","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"data_path = \"../../../data/\" # hide\nkrajbich_data = ADDM.load_data_from_csv(data_path * \"Krajbich2010_behavior.csv\", data_path * \"Krajbich2010_fixations.csv\")","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"note: Note\nNote the organization of data. It is a dictionary where the keys are subject identifiers and values are arrays of ADDM.Trial objects.","category":"page"},{"location":"tutorials/03_empirical_data/#Grid-search","page":"Parameter estimation on empirical data","title":"Grid search","text":"","category":"section"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"Now that we have loaded our data, we define the parameter space over which we'll search to determine the best combination for each subject. We'll use a grid of 64 parameter combinations with d in {0.0001, 0.00015, 0.0002, 0.00025}, μ in {80, 100, 120, 140}, θ in {0.3, 0.5, 0.7, 0.9}  and σ = d*μ   ","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"fn = data_path * \"Krajbich_grid.csv\";\ntmp = DataFrame(CSV.File(fn, delim=\",\"));\nparam_grid = NamedTuple.(eachrow(tmp))","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"Since the dataset contains multiple subjects and we want to compute the best parameters for each subject, we loop through each subject's dataset and collect the estimated parameters in a single data frame for each subject. This is sufficiently fast for this small example but see the parallelization tutorial on how to do this with larger datasets and parameter spaces.","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"all_nlls = DataFrame();\nsubj_mles = Dict();\n\nfor k in keys(krajbich_data)\n  cur_subj_data = krajbich_data[k]\n  \n  output = ADDM.grid_search(cur_subj_data, param_grid, ADDM.aDDM_get_trial_likelihood, Dict(:η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>0, :bias=>0.0), return_grid_nlls = true)\n\n  subj_mles[k] = output[:mle]\n  \n  # Add subject id\n  output[:grid_nlls][!, \"parcode\"] .= k\n\n  append!(all_nlls, output[:grid_nlls])\n  \nend;","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"To view best parameter estimates for each subject we can look at the subj_mles data frame, to which the output of ADDM.grid_search was pushed for each subject.","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"subj_mles","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"As an example visualization below we plot variability in the negative log likelihoods for each parameter combination for each subject. This is not a plot that is typically used for any model diagnostics. The intention is only to show that the likelihood function did indeed compute different values for different parameter combinations.","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"wide_nll_df = unstack(all_nlls, :parcode, :nll);\nselect!(wide_nll_df, Not([:d, :sigma, :theta]));\ncolnames = names(wide_nll_df);\ncolnames = string.(\"subj-\", colnames);\nN = length(colnames);\n\n@df wide_nll_df histogram(cols(1:N); layout=grid(2,5), legend=false, title=permutedims(colnames), frame=:box, titlefontsize=11, c=:blues, bins = 20, size=(1800,1000), xrotation = 45)\n\nsavefig(\"plot_2_1.png\"); nothing # hide","category":"page"},{"location":"tutorials/03_empirical_data/","page":"Parameter estimation on empirical data","title":"Parameter estimation on empirical data","text":"(Image: plot)","category":"page"},{"location":"tutorials/06_parallelization/","page":"-","title":"-","text":"Currently, ADDM.jl relies on some embarassingly parallel data parallelization based on ... By default, ... When using on HPCs  \nSample batch scripts   \nInclude a note on MPI.jl to the parallelization tutorial. One/those familiar with Dask can consider Dagger.jl especially for hierarchical/nested loop ability but at the time of writing these included too much overhead and were not as performant.  \nInclude this discussion: https://discourse.julialang.org/t/is-clustermanagers-jl-maintained-or-how-to-do-multi-node-calculations-in-julia/110050/24  \nInclude this tutorial: https://enccs.github.io/julia-for-hpc/motivation-hpc/  ","category":"page"},{"location":"tutorials/01_getting_started/#Getting-started-with-ADDM.jl","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"","category":"section"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"In this tutorial we will introduce some of the core functionality of the toolbox. We will define an aDDM with specific parameters, simulate choice and response time using those parameters and recover the known parameters from the simulated data.","category":"page"},{"location":"tutorials/01_getting_started/#Load-package","page":"Getting started with ADDM.jl","title":"Load package","text":"","category":"section"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"We begin with loading the packages we'll use in this tutorial.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"using ADDM, CSV, DataFrames, DataFramesMeta\nusing Plots, StatsPlots, Random\nRandom.seed!(38435)","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"note: Note\nNote that the CSV and DataFrames modules must be loaded in addition to ADDM. These are dependencies for the ADDM module but the precompiled module gives access to these dependencies only in the scope of ADDM. In other words, ADDM.load_data_from_csv that requires both of these packages would still work but directly calling functions from these packages would not without importing these modules to the current scope.    ","category":"page"},{"location":"tutorials/01_getting_started/#Parameter-recovery-on-simulated-data","page":"Getting started with ADDM.jl","title":"Parameter recovery on simulated data","text":"","category":"section"},{"location":"tutorials/01_getting_started/#Define-model","page":"Getting started with ADDM.jl","title":"Define model","text":"","category":"section"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"The first component of the toolbox is a parameter container for the model class. This is a key-value pair mapping of parameter names to parameter values. It is a specific kind of dictionary of class ADDM.aDDM. We can create a model container using the ADDM.define_model function.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"MyModel = ADDM.define_model(d = 0.007, σ = 0.03, θ = .6, barrier = 1, \n                decay = 0, nonDecisionTime = 100, bias = 0.0)","category":"page"},{"location":"tutorials/01_getting_started/#Define-stimuli","page":"Getting started with ADDM.jl","title":"Define stimuli","text":"","category":"section"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"The second ingredient to simulating data is to define stimuli. For the pre-defined model in the module, stimuli consist of values associated with the options over which a decision is made. The stimuli should eventually be arranged into a NamedTuple with required field names (case sensitive): valueLeft and valueRight. There are several ways of defining the stimuli within this constraints. Below are a few examples. ","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Option 1: Load stimuli with corresponding fixation data","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"The toolbox comes with some datasets from published research. It also includes a function, ADDM.load_data_from_csv(), that can read in datasets stored in CSVs and wrangles it into a format expected by other functions.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"ADDM.load_data_from_csv() expects columns parcode,trial, rt (optional), choice (optional), item_left, item_right in the CSVs and convert item_left anditem_right to valueLeft and valueRight. It organizes both the behavioral and the fixation data as a dictionary of ADDM.Trial objects indexed by subject. ","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Here, we are reading in empirical data that comes with the package but we will not be making use of the observed choices and response times. This is specified with the stimsOnly argument. The empirical data is only used to extract value difference information to index the fixation data correctly. The choices and response times will be simulated below based on the parameters we specified above.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"data_path = \"../../../data/\"\ndata = ADDM.load_data_from_csv(data_path * \"stimdata.csv\", data_path * \"fixations.csv\"; stimsOnly = true);","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"data is organized as a dictionary with keys corresponding to subject id's and values of arrays containing ADDM.Trials for each subject. Since we are only interested in the values associated with the stimuli, we specify the number of trials we want to simulate (nTrials) and extract that many trials' value information from the data as MyStims.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"nTrials = 1400;\nMyStims = (valueLeft = reduce(vcat, [[i.valueLeft for i in data[j]] for j in keys(data)])[1:nTrials], valueRight = reduce(vcat, [[i.valueRight for i in data[j]] for j in keys(data)])[1:nTrials]);","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Option 2: Read in from CSV  ","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Stimuli can also be read in directly from a file. This approach is simpler to define only the stimuli but would require additional steps to define and organize fixation data.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"fn = data_path * \"rawstims.csv\"\ntmp = DataFrame(CSV.File(fn, delim=\",\"))\nMyStims = (valueLeft = tmp.valueLeft, valueRight = tmp.valueRight)","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Option 3: Create random stimuli","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Alternatively, one can simulate stimuli with random values. Similar to reading in stimulus values directly, this approach would also require additional steps to defne and organize fixation data.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"note: Note\nIf you're going to create random stimuli you should make sure to have value differences that correspond to what you plan to fit in for fixation data.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Random.seed!(38535)\nMyStims = (valueLeft = randn(1000), valueRight = randn(1000))","category":"page"},{"location":"tutorials/01_getting_started/#Define-fixation-data","page":"Getting started with ADDM.jl","title":"Define fixation data","text":"","category":"section"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"The last ingredient to simulate data is fixation patterns. These are necessary because the distinguishing feature of the aDDM is its ability to use eyetracking data to account for attentional biases in choice behavior. Importantly, aDDM treats fixation data as exogenous. This means, that the model does not describe how the fixation patterns arise, but only takes them as given to examine their effects on choice behavior.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"The toolbox has a specific structure for fixation data organized in the  FixationData type. This type organizes empirical fixations to distributions conditional on fixation type (first, second etc.) and value difference.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"First, we extract value difference information from the dataset to use in processing the fixations.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"vDiffs = sort(unique([x.valueLeft - x.valueRight for x in data[\"1\"]]));","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Then we summarize the empricial data from all subjects as distributions from which the model samples from depending on the value difference and the fixation type (1st, 2nd etc.) using ADDM.process_fixations.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"MyFixationData = ADDM.process_fixations(data, fixDistType=\"fixation\", valueDiffs = vDiffs);","category":"page"},{"location":"tutorials/01_getting_started/#Simulate-data","page":"Getting started with ADDM.jl","title":"Simulate data","text":"","category":"section"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Finally, we define additional arguments for the second component of the model, the trial simulator. Here, these are the fixation data, time step for simulations and the maximum length a trial is allowed (in ms). These arguments need to be specified as a NamedTuple, and must have at least two elements. Otherwise the function tries to apply iterate to the single element which would likely end with a  MethodError. In this example, we specify timeStep and cutoff in addition to the  only required argument without a default fixationData to avoid this.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"MyArgs = (timeStep = 10.0, cutOff = 20000, fixationData = MyFixationData);","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Note that these are positional arguments for code efficiency.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"SimData = ADDM.simulate_data(MyModel, MyStims, ADDM.aDDM_simulate_trial, MyArgs);","category":"page"},{"location":"tutorials/01_getting_started/#Recover-parameters-using-a-grid-search","page":"Getting started with ADDM.jl","title":"Recover parameters using a grid search","text":"","category":"section"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Now that we have simulated data with known parameters we can use the third component of the module, the likelihood function to invert the model and recover those parameters from the data.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"The built-in optimization algorithm function for this is ADDM.grid_search. It computes the sum of negative log likelihood across all trials in the data, for each parameter combination specified in param_grid. The parameter space defined in param_grid is organized as an array of NamedTuples indicating the parameter names and their specific values for each combination. For this toy example, the parameter space consists of 27 parameter combinations.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"fn = data_path * \"addm_grid.csv\";\ntmp = DataFrame(CSV.File(fn, delim=\",\"));\nparam_grid = NamedTuple.(eachrow(tmp))","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Having defined the parameter space, we can compute the sum of negative log likelihoods (NLL) for each data point and select the parameter combination with the lowest NLL, which is equivalent to maximizing the likelihood. This combination of parameters is called the maximum likelihood estimate, or the MLE. ADDM.grid_search expects the data, the parameter space, the likelihood function and any fixed parameters for the model as its positional arguments. Additionaly, as a keyword argument, one can specify likelihood_args for values that should be passed onto the likelihood function. Here, we specify the timeStep and the stateStep for solving the Fokker-Planck Equation. The function returns an output dictionary with various components depending on additional arguments that are detailed in other tutorials and the API Reference.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"output = ADDM.grid_search(SimData, param_grid, ADDM.aDDM_get_trial_likelihood, Dict(:η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>100, :bias=>0.0); likelihood_args = (timeStep = 10.0, stateStep = 0.1), return_grid_nlls = true);\n\nmle = output[:mle];\nall_nll_df = output[:grid_nlls];","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Below we display the sum of negative log likelihoods for each parameter combination.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"sort!(all_nll_df, [:nll])","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"note: Note\nYou can save the data containing the negative log likelihood info for all parameter combinations you searched for. Make sure that you have mounted a local directory to your container if you're working through this tutorial in a docker container. The output path below is the one specified in the installation instructions. You should change it if you want to save your output elsewhere.output_path = '/home/jovyan/work/all_nll_df.csv'\nCSV.write(output_path, all_nll_df)","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"You might have noticed that the grid search did not identify the true parameters (d = 0.007, σ = 0.03, θ = .6) as the ones with the highest likelihood. This highlights the importance of choosing good stepsizes for the temporal and spatial discretization. Let's reduce the spatial step size and see if we can recover the corect parameter combination.","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"my_likelihood_args = (timeStep = 10.0, stateStep = 0.01)\n\noutput = ADDM.grid_search(SimData, param_grid, ADDM.aDDM_get_trial_likelihood, Dict(:η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>100, :bias=>0.0), likelihood_args=my_likelihood_args);\n\nmle = output[:mle];\nmle","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Success! Reducing the state step size was sufficient to recover the true parameter combination for the simulated dataset. ","category":"page"},{"location":"tutorials/01_getting_started/","page":"Getting started with ADDM.jl","title":"Getting started with ADDM.jl","text":"Ok, but what happened there? That's what we detail in the next tutorial.","category":"page"},{"location":"apireference/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"apireference/#Core-types","page":"API Reference","title":"Core types","text":"","category":"section"},{"location":"apireference/","page":"API Reference","title":"API Reference","text":"ADDM.Trial\nADDM.aDDM\nADDM.define_model","category":"page"},{"location":"apireference/#ADDM.Trial","page":"API Reference","title":"ADDM.Trial","text":"Trial(choice, RT, valueLeft, valueRight)\n\nArguments\n\nRequired keyword arguments\n\nchoice: either -1 (for left item) or +1 (for right item).\nRT: response time in milliseconds.\nvalueLeft: value of the left item.\nvalueRight: value of the right item.\n\nOptional\n\nfixItem: list of items fixated during the trial in chronological   order; 1 correponds to left, 2 corresponds to right, and any   other value is considered a transition/blank fixation.\nfixTime: list of fixation durations (in milliseconds) in   chronological order.\nfixRDV: list of Float64 corresponding to the RDV values at the end of   each fixation in the trial.\nuninterruptedLastFixTime: Int64 corresponding to the duration, in   milliseconds, that the last fixation in the trial would have if it   had not been interrupted when a decision was made.\nRDV: vector of RDV over time.\n\nExample\n\njulia> t = Trial(choice = 1, RT = 2145, valueLeft = 1, valueRight = 3)\nTrial(1, 2145, 1, 3, #undef, #undef, #undef, #undef, #undef)\n\njulia> t.RT\n2145\n\njulia> t.uninterruptedLastFixTime\nERROR: UndefRefError: access to undefined reference\nStacktrace:\n [1] getproperty(x::Trial, f::Symbol)\n   @ Base ./Base.jl:37\n [2] top-level scope\n   @ REPL[4]:1\n\njulia> t.uninterruptedLastFixTime = 189\n189\n\njulia> t\nTrial(1, 2145, 1, 3, #undef, #undef, #undef, 189, #undef)\n\n\n\n\n\n","category":"type"},{"location":"apireference/#ADDM.aDDM","page":"API Reference","title":"ADDM.aDDM","text":"Constructor for model definitions that will contain model parameter and parameter value   mapping. Not intended to be used alone but as part of define_model\n\nExample\n\njulia> MyModel = ADDM.aDDM()\naDDM(Dict{Symbol, Any}())\n\njulia> MyModel.d = 0.005\n0.005\n\njulia> MyModel.σ = .06\n0.06\n\njulia> MyModel\naDDM(Dict{Symbol, Any}(:σ => 0.06, :d => 0.005))\n\n\n\n\n\n","category":"type"},{"location":"apireference/#ADDM.define_model","page":"API Reference","title":"ADDM.define_model","text":"define_model(d, σ, θ = 1, η = 0, barrier = 1, decay = 0, nonDecisionTime = 0, bias = 0.0)\n\nCreate attentional drift diffusion model with parameters described in    Krajbich et al. (2010).\n\nArguments\n\nRequired parameters\n\nd: Number, parameter of the model which controls the speed of   integration of the signal.\nσ: Number, parameter of the model, standard deviation for the   normal distribution.\n\nOptional parameters\n\nθ: Float64 Traditionally between 0 and 1, parameter of the model which controls   the attentional discounting. Default at 1 makes it a ddm.\nη: Float64 Additive attentional enhancement the attentional discounting.    Default at 0 makes it a ddm.\nbarrier: positive Int64, boundary separation in each direction from 0. Default at 1.\ndecay: constant for linear barrier decay at each time step. Default at 0.\nnonDecisionTime: non-negative Number, the amount of time in   milliseconds during which processes other than evidence accummulation occurs.    Default at 0.\nbias: Number, corresponds to the initial value of the relative decision value   variable. Must be smaller than barrier.\n\nTodo\n\nTests\nChange decay parameter to function instead of scalar\n\nExample\n\njulia julia> MyModel = define_model(d = .006, σ = 0.05) aDDM(Dict{Symbol, Any}(:nonDecisionTime => 0, :σ => 0.05, :d => 0.006, :bias => 0.0, :barrier => 1, :decay => 0, :θ => 1.0, :η => 0.0))`\n\n\n\n\n\n","category":"function"},{"location":"apireference/#Fixation-data","page":"API Reference","title":"Fixation data","text":"","category":"section"},{"location":"apireference/","page":"API Reference","title":"API Reference","text":"ADDM.FixationData   \nADDM.process_fixations  \nADDM.convert_to_fixationDist  ","category":"page"},{"location":"apireference/#ADDM.FixationData","page":"API Reference","title":"ADDM.FixationData","text":"FixationData(probFixLeftFirst, latencies, transitions, fixations; \n             fixDistType=\"fixation\")\n\nArguments:\n\nprobFixLeftFirst: Float64 between 0 and 1, empirical probability that   the left item will be fixated first.\nlatencies: Vector corresponding to the empirical distribution of   trial latencies (delay before first fixation) in milliseconds.\ntransitions: Vector corresponding to the empirical distribution   of transitions (delays between item fixations) in milliseconds.\nfixations: Dict whose indexing is defined according to parameter   fixDistType. Each entry is an array corresponding to the   empirical distribution of item fixation durations in   milliseconds.\nfixDistType: String, one of {'simple', 'difficulty', 'fixation'},   determines how the fixation distributions are indexed. If   'simple', fixation distributions are indexed only by type (1st,   2nd, etc). If 'difficulty', they are indexed by type and by trial   difficulty, i.e., the absolute value for the trial's value   difference. If 'fixation', they are indexed by type and by the   value difference between the fixated and unfixated items.\n\n\n\n\n\n","category":"type"},{"location":"apireference/#ADDM.process_fixations","page":"API Reference","title":"ADDM.process_fixations","text":"process_fixations(data::Dict; timeStep::Number = 10, \n                                 maxFixTime::Number = 3000, \n                                 numFixDists::Int64 = 3, fixDistType::String = \"fixation\", \n                                 valueDiffs::Vector{Int64} = collect(-3:1:3), \n                                 subjectIds::Vector{String} = String[])\n\nCreate empirical distributions from the data to be used when generating model simulations.\n\nArguments\n\ndata: a dict, indexed by subjectId, where each entry is a list of   Trial objects. E.g. output of load_data_from_csv\ntimeStep: integer, minimum duration of a fixation to be considered, in   miliseconds.\nmaxFixTime: integer, maximum duration of a fixation to be considered, in   miliseconds.\nnumFixDists: integer, number of fixation types to use in the fixation   distributions. For instance, if numFixDists equals 3, then 3 separate   fixation types will be used, corresponding to the 1st, 2nd and other   (3rd and up) fixations in each trial.\nfixDistType: string, one of {'simple', 'difficulty', 'fixation'}, used to   determine how the fixation distributions should be indexed. If   'simple', then fixation distributions will be indexed only by type   (1st, 2nd, etc). If 'difficulty', they will be indexed by type and by   trial difficulty, i.e., the absolute value for the trial's value   difference. If 'fixation', they will be indexed by type and by the   value difference between the fixated and unfixated items. Note that    this is not the same as the value difference for the trial. \nvalueDiffs: list of integers. If fixDistType is 'difficulty' or   'fixation', valueDiffs is a range correspoding to the item values to   be used when indexing the fixation distributions. So if difficulty   make sure to input absolute value differences if that is the measure   of difficulty of the decision.\nsubjectIds: list of strings corresponding to the subjects whose data   should be used. If not provided, all existing subjects will be used.\n\nReturn\n\nA FixationData object.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#ADDM.convert_to_fixationDist","page":"API Reference","title":"ADDM.convert_to_fixationDist","text":"convert_to_fixationDist(fixationData::FixationData; timeStep::Number = 10)\n\nCreate empirical distributions from the data to be used when generating model simulations.\n\nArguments\n\nfixationData: FixationData type that is the output of process_fixations.\ntimeStep: integer, timeBin size in ms.\n\nReturn\n\nfixationDist: Dictionary indexed by value difference and fixation type. Contains the distributions of fixation durations in each time bin specifiu\ntimeBinMidPoints: Mid points of the time bins, for which the fixation  duration distributions were calculated. Will be the durations sampled in  addm_simulate_trial if using fixationDist instead of fixationData\n\n\n\n\n\n","category":"function"},{"location":"apireference/#Data-simulation","page":"API Reference","title":"Data simulation","text":"","category":"section"},{"location":"apireference/","page":"API Reference","title":"API Reference","text":"ADDM.aDDM_simulate_trial\nADDM.DDM_simulate_trial\nADDM.simulate_data","category":"page"},{"location":"apireference/#ADDM.aDDM_simulate_trial","page":"API Reference","title":"ADDM.aDDM_simulate_trial","text":"aDDM_simulate_trial(model::aDDM, fixationData::FixationData, \n                    valueLeft::Number, valueRight::Number; timeStep::Number=10.0, \n                    numFixDists::Int64=3 , fixationDist=nothing, timeBins=nothing, \n                    cutOff::Number=100000)\n\nGenerate a DDM trial given the item values.\n\nArguments\n\nmodel: aDDM object.\nfixationData: FixationData object. Required even when using fixationDist because it specifies latencies and transitions as well.\nvalueLeft: value of the left item.\nvalueRight: value of the right item.\ntimeStep: Number, value in milliseconds to be used for binning   time axis.\nnumFixDists: Int64, number of fixation types to use in the fixation   distributions. For instance, if numFixDists equals 3, then 3   separate fixation types will be used, corresponding to the 1st,   2nd and other (3rd and up) fixations in each trial.\nfixationDist: distribution of fixations which, when provided, will be   used instead of fixationData.fixations. This should be a dict of   dicts of dicts, corresponding to the probability distributions of   fixation durations. Indexed first by fixation type (1st, 2nd, etc),   then by the value difference between the fixated and unfixated    items, then by time bin. Each entry is a number between 0 and 1    corresponding to the probability assigned to the particular time   bin (i.e. given a particular fixation type and value difference,   probabilities for all bins should add up to 1). Can be obtained from   fixationData using convert_to_fixationDist. If using this instead   of fixationData to sample fixations make sure to specify latency and    transition info in fixationData.\ntimeBins: array containing the time bins used in fixationDist. Can be   obtained fromfixationData using convert_to_fixationDist\n\nReturns\n\nAn Trial object resulting from the simulation.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#ADDM.DDM_simulate_trial","page":"API Reference","title":"ADDM.DDM_simulate_trial","text":"DDM_simulate_trial(model::aDDM, valueLeft::Number, valueRight::Number; timeStep::Number = 10.0, \n                   cutOff::Int64 = 20000)\n\nGenerate a DDM trial given the item values.\n\nArguments\n\nmodel: aDDM object.\nvalueLeft: value of the left item.\nvalueRight: value of the right item.\ntimeStep: Number, value in milliseconds to be used for binning the   time axis.\ncutOff: Number, value in milliseconds to be used as a cap if trial   response time is too long.\nReturns\nA Trial object resulting from the simulation.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#ADDM.simulate_data","page":"API Reference","title":"ADDM.simulate_data","text":"simulate_data(model::aDDM, stimuli, simulator_fn, simulator_args = (timeStep = 10.0, cutOff = 20000))\n\nSimulate data using the model for the given stimuli.\n\nArguments\n\nmodel: aDDM object.\nstimuli: Named tuple with valueLeft and valueRight specifying the values of options.\nsimulator_fn: Name of the function that simulates a trial for the given model.\nsimulator_args: Named tuple containing kwargs that should be fed to simulator_fn\n\nReturns\n\nVector of Trial objects containing simulated data.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#Likelihood-computation","page":"API Reference","title":"Likelihood computation","text":"","category":"section"},{"location":"apireference/","page":"API Reference","title":"API Reference","text":"ADDM.aDDM_get_trial_likelihood\nADDM.DDM_get_trial_likelihood\nADDM.compute_trials_nll","category":"page"},{"location":"apireference/#ADDM.aDDM_get_trial_likelihood","page":"API Reference","title":"ADDM.aDDM_get_trial_likelihood","text":"aDDM_get_trial_likelihood(;addm::aDDM, trial::Trial, timeStep::Number = 10.0, \n                          stateStep::Number = 0.01)\n\nCompute the likelihood of the data from a single aDDM trial for these particular aDDM    parameters.\n\nArguments:\n\nKeyword arguments\n\nmodel: aDDM object.\ntrial: Trial object.\ntimeStep: Number, value in milliseconds to be used for binning the   time axis.\nstateStep: Number, to be used for binning the RDV axis.\n\nReturns:\n\nThe likelihood obtained for the given trial and model.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#ADDM.DDM_get_trial_likelihood","page":"API Reference","title":"ADDM.DDM_get_trial_likelihood","text":"DDM_get_trial_likelihood(;ddm::aDDM, trial::Trial, timeStep::Number = 10, \n                         stateStep::Number = 0.01)\n\nCompute the likelihood of the data from a single DDM trial for these particular DDM parameters.\n\nArguments\n\nKeyword arguments\n\nmodel: aDDM object.\ntrial: Trial object.\ntimeStep: Number, value in milliseconds to be used for binning the   time axis.\nstateStep: Number, to be used for binning the RDV axis.\n\nReturns\n\nThe likelihood obtained for the given trial and model.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#ADDM.compute_trials_nll","page":"API Reference","title":"ADDM.compute_trials_nll","text":"compute_trials_nll(model::aDDM, data, likelihood_fn, likelihood_args = (timeStep = 10.0, cutOff = 20000))\n\nCompute likelihood of a dataset for a given model.\n\nArguments\n\nmodel: aDDM object. Holds info on the parameter values for the likelihood function.\ndata: Vector of ADDM.Trial objects. \nlikelihood_fn: Name of the function that computes the likelhoods of a trial for the given model.\nlikelihood_args: Named tuple containing kwargs that should be fed to likelihood_fn\nreturn_trial_likelihoods: Boolean to specify whether to return the likelihoods for each trial\nsequential_model: Boolean to specify if the model requires all data concurrently (e.g. RL-DDM). If true model cannot be multithreaded\n\nReturns\n\nNegative log likelihood of data\n(Optional) Dictionary of trial likelihoods keyed by the trial number\n\n\n\n\n\n","category":"function"},{"location":"apireference/#Grid-search","page":"API Reference","title":"Grid search","text":"","category":"section"},{"location":"apireference/","page":"API Reference","title":"API Reference","text":"ADDM.setup_fit_for_params\nADDM.get_trial_posteriors\nADDM.save_intermediate_likelihoods_fn\nADDM.match_param_grid_keys\nADDM.get_mle\nADDM.grid_search","category":"page"},{"location":"apireference/#ADDM.setup_fit_for_params","page":"API Reference","title":"ADDM.setup_fit_for_params","text":"setup_fit_for_params(fixed_params, likelihood_fn, cur_grid_params, likelihood_fn_module=Main)\n\nReturn parameter container and likelihood function for given parameter combination.\n\nArguments\n\nfixed_params: Model parameters that are fixed to a value and not fitted.\nlikelihood_fn: Name of likelihood function.\ncur_grid_params: NamedTuple containing the parameter combination\nlikelihood_fn_module: Default Main. Module where the likelihood function is defined.\n\nReturns\n\nmodel: Container holding parameter combination info.\nlikelihood_fn: Likelihood function that computes trial likelihoods for a given parameter combination.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#ADDM.get_trial_posteriors","page":"API Reference","title":"ADDM.get_trial_posteriors","text":"get_trial_posteriors(param_grid, model_priors, trial_likelihoods)\n\nCompute model posteriors after each trial given model priors and trialwise likelihoods.\n\nArguments\n\nparam_grid: Vector of NamedTuples defining parameter space.\nmodel_priors: Dictionary with parameter combinations as keys and prior model probability as values.\ntrial_likelihoods: Nested dictionary with outer keys of parameter combinations, inner keys of trial numbers, and values of trial likelihoods.\n\nReturns\n\ntrial_posteriors: Nested dictionary with outer keys of parameter combinations, inner keys of trial numbers, and values of model posterior probabilities after each observation.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#ADDM.save_intermediate_likelihoods_fn","page":"API Reference","title":"ADDM.save_intermediate_likelihoods_fn","text":"save_intermediate_likelihoods(trial_likelihoods_for_grid_params, cur_grid_params, save_path)\n\nWrite out trial likelihoods as soon as they are computed for a given parameter combination. Intended   to be used when running a large parameter grid and worried that job might fail unexpectedly. Saved   trial likelihoods can later be read in to compute posteriors if necessary.\n\nArguments\n\ntrial_likelihoods_for_grid_params: Dictionary with keys of trial numbers and values of likelihoods for cur_grid_params.\ncur_grid_params: parameter combination, for which the likelihoods are being saved. NamedTuple entry in  param_grid.\nsave_path: Path to save the intermediate output. Default to \"./outputs\" which saves output to directory from which the function is run (creates it if needed). \nfn: File name for the saved output. \".csv\" will be appended to this string.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#ADDM.match_param_grid_keys","page":"API Reference","title":"ADDM.match_param_grid_keys","text":"match_param_grid_keys(param_grid)\n\nIf paramgrid contains models with different parameter names, ensure all entries in    paramgrid have the same names and assigns a \"NA\" if that parameter names does not exist for   a given model.\n\nArguments\n\nparam_grid: Vector of NamedTuples with parameter names as keys and parameter values as values.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#ADDM.get_mle","page":"API Reference","title":"ADDM.get_mle","text":"get_mle(all_nll, likelihood_args)\n\nExtract maximum likelihood estimate from all_nll\n\nArguments\n\nall_nll: Dictionary containing parameter combinations as keys and sum of negative log likelihoods   as values.\nlikelihood_args: NamedTuple containing step size info.\n\nReturn\n\nbest_pars: MLE amongst the parameter combinations tried in all_nll for step sizes specified in  likelihood_args\n\n\n\n\n\n","category":"function"},{"location":"apireference/#ADDM.grid_search","page":"API Reference","title":"ADDM.grid_search","text":"grid_search(data, param_grid, likelihood_fn = nothing, \n            fixed_params = Dict(:θ=>1.0, :η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>0, :bias=>0.0); \n            likelihood_args = (timeStep = 10.0, stateStep = 0.01), \n            model_priors = nothing,\n            likelihood_fn_module = Main,\n            sequential_model = false,\n            grid_search_exec = ThreadedEx(),\n            compute_trials_exec = ThreadedEx(),\n            return_grid_nlls = false,\n            return_model_posteriors = false,\n            return_trial_posteriors = false,\n            save_intermediate_likelihoods = false,\n            noise_param_name = \"sigma\")\n\nCompute the likelihood of either observed or simulated data for all parameter combinations in param_grid.\n\nArguments\n\nRequired\n\ndata: Data for which the sum of negative log likelihoods will be computed for each trial. Should be a vector of ADDM.Trial objects.\nparam_grid: Parameter combinations for which the sum of nll's for the data is  computed. Vector of NamedTuples. E.g. ```\n\n15-element Vector{@NamedTuple{d::Float64, sigma::Float64, theta::Float64, likelihoodfn::String}}:   (d = 0.001, sigma = 0.01, theta = 0.12, likelihoodfn = \"ADDM.aDDMgettriallikelihood\")   (d = 0.002, sigma = 0.01, theta = 0.12, likelihoodfn = \"ADDM.aDDMgettrial_likelihood\")   ...  ```\n\nlikelihood_fn: Name of likelihood function to be used to compute likelihoods.  The toolbox has ADDM.aDDM_get_trial_likelihood and ADDM.DDM_get_trial_likelihood defined. If comparing different generative processes then leave at default value of nothing and make sure to define a likelihood_fn in the param_grid.\nfixed_params: Default Dict(:θ=>1.0, :η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>0, :bias=>0.0). Parameters required by the likelihood_fn that are not specified to vary across likelihood  computations.\nlikelihood_args: Default (timeStep = 10.0, stateStep = 0.01). Additional  arguments to be passed onto likelihood_fn. \n\nOptional\n\nmodel_priors: priors for each model probability if not assummed to be uniform. Should be specified as a Dict with values of probabilities matching the keys for the parameter combinations specified in param_grid.\nlikelihood_fn_module: Default Main. Scope from which to pull the likelihood function. Default works for custom functions defined inline or in a script, as well as, the built-in functions.\nsequential_model: Boolean to specify if the model requires all data concurrently (e.g. RL-DDM). If true  likelihood computation for model cannot be multithreaded (though grid search still can be).\ngrid_search_exec: Executor used by FLoops.jl to parallelize computation of nll for each parameter  combination over threads. Default is ThreadedEx(). Other options are DistributedEx() and SequentialEx(). See FLoops.jl documentation for more details.\ncompute_trials_exec: Executor used by FLoops.jl to parallelize computation of each trial's likelihood over threads. Default is ThreadedEx(). Other options are DistributedEx() and SequentialEx(). See FLoops.jl  documentation for more details.\nreturn_grid_nlls: Default false. If true, will return a DataFrame containing the sum of nll's for  each parameter combination in the grid search.\nreturn_model_posteriors: Default false. If true, will return the posterior probability  for each parameter combination in param_grid.\nreturn_trial_posteriors: Default false. If true, will return the posterior probability  for each parameter combination in param_grid after each trial in data.  \nsave_intermediate_likelihoods: Default false. If true, will crate a csv containing the likelihoods for each  trial after it is computed for a given parameter combination. Could be useful if doing a large parameter sweep  and are worried about the job terminating unexpectedly. Job could be restarted for parameter combinations, for  which the trial likelihoods have not been saved, instead of all parameter combinations. \nnoise_param_name: Default \"sigma\". String specifying the name of the noise parameter in the model. Used  to check stability criterion for Forward Euler.\n\nReturns\n\noutput: Dict with keys:\nbest_pars: Dict containing the parameter combination with the lowest nll.\ngrid_nlls: (Optional) DataFrame containing sum of nll's for each parameter combination.\ntrial_posteriors: (Optional) Posterior probability for each parameter combination after each trial.\nmodel_posteriors: (Optional) Posterior probability for each parameter combination after all trials.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#Marginal-posteriors","page":"API Reference","title":"Marginal posteriors","text":"","category":"section"},{"location":"apireference/","page":"API Reference","title":"API Reference","text":"ADDM.marginal_posteriors\nADDM.marginal_posterior_plot","category":"page"},{"location":"apireference/#ADDM.marginal_posteriors","page":"API Reference","title":"ADDM.marginal_posteriors","text":"marginal_posteriors(posteriors_dict, two_d_marginals)\n\nCompute the marginal posterior distributions for the fitted parameters specified in param_grid.\n\nArguments\n\nRequired\n\nposteriors_dict: Dictionary of posterior model probabilities. Keys of this dictionary are  the parameter combinations specified in param_grid. Values are the posterior probabilties  after accounting for each observation.\ntwo_d_marginals: Boolean. Whether to compute posteriors to plot heatmaps of posteriors. Default is false.\n\nReturns\n\nVector of DataFrames. If two_d_marginals is false, return only dataframes containing posteriors for each parameter. Otherwise, also includes posteriors for pairwise combinations of  parameters as well.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#ADDM.marginal_posterior_plot","page":"API Reference","title":"ADDM.marginal_posterior_plot","text":"marginal_posterior_plot\n\nThis plot type shows the posteriors for each parameter individually,     as well as the posterior probabilities of pairwise combinations.  \n\nThe input is an array of dataframes resulting from ADDM.marginal_posteriors   with the third positional argument set to true.\n\nbest_pars, nll_df, model_posteriors = ADDM.grid_search(subj_data, ADDM.aDDM_get_trial_likelihood, param_grid, \n    Dict(:η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>0, :bias=>0.0), \n    likelihood_args=my_likelihood_args, \n    return_model_posteriors = true)\n\nADDM.marginal_posteriors(param_grid, model_posteriors, true)\n\nRecipe modified from  https://github.com/JuliaPlots/StatsPlots.jl/blob/master/src/corrplot.jl\n\n\n\n\n\n","category":"function"},{"location":"apireference/#Helpers","page":"API Reference","title":"Helpers","text":"","category":"section"},{"location":"apireference/","page":"API Reference","title":"API Reference","text":"ADDM.load_data_from_csv\nADDM.convert_param_text_to_symbol","category":"page"},{"location":"apireference/#ADDM.load_data_from_csv","page":"API Reference","title":"ADDM.load_data_from_csv","text":"load_data_from_csv(expdataFileName, fixationsFileName; stimsOnly = false)\n\nLoad experimental data from two CSV files: an experimental data file and a fixations file. Format expected for experimental data file: parcode, trial, rt, choice, itemleft, itemright. Format expected for fixations file: parcode, trial, fixitem, fixtime.\n\nArguments\n\nPositional\n\nexpdataFileName: String, name of experimental data file.\nfixationsFileName: String, name of fixations file.\nparcode: Subject identifier\ntrial: Trial number\nfix_item: Fixation location. 0 = transition, 1 = left, 2 = right,\n3 = latency.\nfix_time: Fixation duration.\n\nKeyword\n\nstimsOnly: Boolean, true if expdataFileName contains only stimuli info and no choice or rt info.\n\nReturn\n\nA dict, indexed by subjectId, where each entry is a list of Trial       objects.\n\n\n\n\n\n","category":"function"},{"location":"apireference/#ADDM.convert_param_text_to_symbol","page":"API Reference","title":"ADDM.convert_param_text_to_symbol","text":"convert_param_text_to_symbols(model)\n\nConvert parameter names that are specified in text into greek/latex symbols. Used by ADDM.grid_search\n\n\n\n\n\n","category":"function"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Documentation)  (Image: CI)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Welcome to ADDM.jl, a package for  joint modeling of response times, eyetracking data and choice behavior using evidence accummulations models with time-varying drift rates. ","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"#Currently","page":"Home","title":"Currently","text":"","category":"section"},{"location":"#Docker","page":"Home","title":"Docker","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This option is for those who don't want to deal with installing any dependencies. See below for instructions on how to install via Github","category":"page"},{"location":"","page":"Home","title":"Home","text":"Install and start Docker Desktop\nFrom the command line interface you have for your sistem\nRun the command below to start a Julia REPL. Note that this will mount your current working directory onto a path in the container so you can save your outputs locally if needed (more on this below)\ndocker run -it --rm \\\n-v $(pwd):/home/jovyan/work \\\nrnlcaltech/addm-toolbox:addm.jl\nOr start a notebook in a container based on the image using the command.   \ndocker run -it --rm \\\n-v $(pwd):/home/jovyan/work \\\n-p 8888:8888 rnlcaltech/addm-toolbox:addm.jl jupyter-lab\ndocker run -it --rm: this is the main command to start a container from an image. The two flags are -it to interact with the container interactively and --rm so docker cleans up after we're done with the container\n-v $(pwd):/home/jovyan/work: this mounts your local directory, wherever you're running this command from as captured by $(pwd) on to the file system in the docker image at path /home/jovyan/work. You can change either side of : to mount another directory from your system or to another path in the container. This part is critical if you want to be able to write out and save any output from your analyses that run in the container. Otherwise they will disappear when you kill the container (because we are starting the container with the --rm flag).\n-p 8888:8888: this connects a local port to the jupyter-lab port in the container. If you have any other jupyter-lab notebooks running locally that are listening on the 8888 port you should change this to e.g. -p 8989:8888 so it does not ask you for a token when you go to the URL this command lists in its output.\nrnlcaltech/addm-toolbox:addm.jl jupyter-lab: this specifies the container name with the tag and the entry point (the beginning command) you want to run in the container. The output will look similar to when you start a jupyter notebook locally. Go to the URL listed in the output in a browser to start a notebook and begin exploring the toolbox as described in Getting started with ADDM.jl\nTo kill the container hit cmd + c","category":"page"},{"location":"#Github","page":"Home","title":"Github","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you have Julia and Git installed and want a local copy of the toolbox on your machine you can follow the intructions below. Note that, this will require you to install all Julia dependencies (in it's own environmet).","category":"page"},{"location":"","page":"Home","title":"Home","text":"Clone the Github repo","category":"page"},{"location":"","page":"Home","title":"Home","text":"git clone https://github.com/aDDM-Toolbox/ADDM.jl.git","category":"page"},{"location":"","page":"Home","title":"Home","text":"Navigate to the ADDM.jl directory","category":"page"},{"location":"","page":"Home","title":"Home","text":"cd ADDM.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"Set up the Julia environment (might take a few minutes)","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia --project -e 'import Pkg; Pkg.instantiate()'","category":"page"},{"location":"","page":"Home","title":"Home","text":"Start up a Julia REPL using the project's environment","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia --project={path_to}/ADDM.jl","category":"page"},{"location":"#Once-ADDM.jl-is-on-the-Julia-Registry","page":"Home","title":"Once ADDM.jl is on the Julia Registry","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can install ADDM.jl from the Julia Registry if you want a local copy of it. Alternatively you can use the Docker images as described above.","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> import Pkg\n\njulia> Pkg.add(\"ADDM\")","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ADDM.jl is licensed under the GNU General Public License v3.0.","category":"page"},{"location":"#Resources-for-getting-started","page":"Home","title":"Resources for getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"There are a few ways to get started with ADDM.jl:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Become familiar with the modeling framework described in Krajbich et al. (2010)  \nBecome familiar with algorithm used for likelihood computation in Tavares et al. (2017)  \nRead the introductory tutorial","category":"page"},{"location":"#Getting-help","page":"Home","title":"Getting help","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you need help, please open a GitHub issue.","category":"page"},{"location":"#Citing-ADDM.jl","page":"Home","title":"Citing ADDM.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use ADDM.jl, we ask that you please cite the following:","category":"page"},{"location":"tutorials/02_likelihood_computation/#Likelihood-computation-in-ADDM.jl","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"","category":"section"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"How do we estimate parameters? We choose a measure to quantify the difference between observed/empirical data and data that would be generated","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"For sequential sampling models these can be ...","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"A very common metric in all kinds of applications is likelihood","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"What is the likelihood in the context of sequential sampling models? It is the probability of observing the endorsed choice at the observed response time. This second part is what makes these models powerful. This is what we mean by the \"joint\" modeling of choice and response times.","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"So how do we calculate the likelihood for sequential sampling models? There are a few ways","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"The analytical solution of the Wiener First Passage Time distribution\nTrialwise simulations\nApproximate Bayesian Computation\nSolving the Fokker Planck Equation","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"The likelihood functions in ADDM.jl use the last method.","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"Briefly, the FPE describes how a probability distribution changes over time. Since it is an expression of change, formally it is written as a partial differential equation. We'll skip the details of the math here but for an in depth dive, please see Shinn et al.","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"Here, we'll try to keep things intuitive. ","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"[ADD Gabi's supplementary figure here]","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"Ok so what is the effect of the discretization step sizes (in both time and space)","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"using ADDM, CSV, DataFrames, DataFramesMeta\nusing Plots, StatsPlots, Random, Plots.PlotMeasures\nRandom.seed!(38435)\n\nMyModel = ADDM.define_model(d = 0.007, σ = 0.03, θ = .6, barrier = 1, \n                       decay = 0, nonDecisionTime = 100, bias = 0.0)\n\ndata_path = \"../../../data/\" \ndata = ADDM.load_data_from_csv(data_path * \"stimdata.csv\", data_path * \"fixations.csv\"; stimsOnly = true);\n\nnTrials = 1400;\n\nMyStims = (valueLeft = reduce(vcat, [[i.valueLeft for i in data[j]] for j in keys(data)])[1:nTrials], valueRight = reduce(vcat, [[i.valueRight for i in data[j]] for j in keys(data)])[1:nTrials]);\n\nvDiffs = sort(unique([x.valueLeft - x.valueRight for x in data[\"1\"]]));\n\nMyFixationData = ADDM.process_fixations(data, fixDistType=\"fixation\", valueDiffs = vDiffs);\n\nMyArgs = (timeStep = 10.0, cutOff = 20000, fixationData = MyFixationData);\n\nSimData = ADDM.simulate_data(MyModel, MyStims, ADDM.aDDM_simulate_trial, MyArgs);","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"We can look at a few things. ","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"Save intermediate likelihoods for all trials with stepSize = .1 vs .01 for the correct and incorrect parameters","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"param_grid = [(d = 0.007, sigma = 0.03, theta = 0.6), (d = 0.007, sigma = 0.05, theta = 0.6)];\n\noutput_large = ADDM.grid_search(SimData, param_grid, ADDM.aDDM_get_trial_likelihood, Dict(:η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>100, :bias=>0.0), likelihood_args = (timeStep = 10.0, stateStep = 0.1), save_intermediate_likelihoods = true , intermediate_likelihood_path=\"./outputs/\", intermediate_likelihood_fn=\"large_stateStep_likelihoods\");\n\noutput_small = ADDM.grid_search(SimData, param_grid, ADDM.aDDM_get_trial_likelihood, Dict(:η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>100, :bias=>0.0), likelihood_args = (timeStep = 10.0, stateStep = 0.01), save_intermediate_likelihoods = true, intermediate_likelihood_path=\"./outputs/\", intermediate_likelihood_fn=\"small_stateStep_likelihoods\");","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"fns = [\"large\", \"small\"];\n\ntrial_likelihoods_for_sigmas = DataFrame();\nfor fn in fns\n  trial_likelihoods = DataFrame(CSV.File(\"./outputs/\"* fn *\"_stateStep_likelihoods.csv\", delim=\",\"))\n  cur_tlfs = unstack(trial_likelihoods, :trial_num, :sigma, :likelihood)\n  cur_tlfs[!, :stateStep] .= fn * \" stateStep\"\n  trial_likelihoods_for_sigmas = vcat(trial_likelihoods_for_sigmas, cur_tlfs)\nend\nrename!(trial_likelihoods_for_sigmas, [Symbol(0.05), Symbol(0.03)]  .=> [:incorrect_sigma, :correct_sigma])\n\nax_lims = (minimum(vcat(trial_likelihoods_for_sigmas.incorrect_sigma, trial_likelihoods_for_sigmas.correct_sigma)), maximum(vcat(trial_likelihoods_for_sigmas.incorrect_sigma, trial_likelihoods_for_sigmas.correct_sigma)))\n\n@df trial_likelihoods_for_sigmas scatter(:correct_sigma, :incorrect_sigma,\n                                          xlabel = \"Likelihoods for true parameters\", \n                                          ylabel = \"Likelihoods for incorrect parameters\", \n                                          lim = ax_lims,\n                                          group = :stateStep,\n                                          m = (0.5, [:x :+], 4))\nPlots.abline!(1, 0, line=:dash, color=:black, label=\"\")\n","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"Pick a few trials where the likelihoods differ a lot between the correct and incorrect parameters. Use the debug option in the aDDM_get_trial_likelihood to plot the propogation of the probability distribution across timeSteps","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"# make new column for the difference in likelihoods for correct vs incorrect sigma \n@transform!(trial_likelihoods_for_sigmas, :diff_likelihood = :incorrect_sigma - :correct_sigma)\n\n# order by that difference column\n@orderby(trial_likelihoods_for_sigmas, -:diff_likelihood)\n\n# Pick top 4 trials (or maybe just one)\ndiff_trial_nums = [@orderby(trial_likelihoods_for_sigmas, -:diff_likelihood)[1,:trial_num]];\n\n# extract these from the data\ndiff_trials = SimData[diff_trial_nums];","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"Plot probStates for each trial with small vs large stateStep for correct and incorrect model","category":"page"},{"location":"tutorials/02_likelihood_computation/","page":"Likelihood computation in ADDM.jl","title":"Likelihood computation in ADDM.jl","text":"# 2 x 2 plot\n# Rows are stepsize\n# Cols are models\n# Point is to show that likelihood value changes depending on stepsize\n# Colors must match across the four plots\n# Need a legend common to all\n# Why are the prStates plots with small stepsize so dark?\n# Because the values in each bin are very small. \n# They values in each bin are small because they are spread over 10 times as many bins.\n\ncorrect_model = MyModel\nincorrect_model = ADDM.define_model(d = 0.007, σ = 0.05, θ = .6, barrier = 1, \n                decay = 0, nonDecisionTime = 100, bias = 0.0)\n\n\n# Use aDDM_get_trial_likelihood with debug = true to get probStates and probUp and \n_, prStates_cm_ls, probUpCrossing_cm_ls, probDownCrossing_cm_ls = ADDM.aDDM_get_trial_likelihood(;model = correct_model, trial = diff_trials[1], timeStep = 10.0, stateStep = 0.1, debug = true)\n\n_, prStates_cm_ss, probUpCrossing_cm_ss, probDownCrossing_cm_ss = ADDM.aDDM_get_trial_likelihood(;model = correct_model, trial = diff_trials[1], timeStep = 10.0, stateStep = 0.01, debug = true)\n\n_, prStates_im_ls, probUpCrossing_im_ls, probDownCrossing_im_ls = ADDM.aDDM_get_trial_likelihood(;model = incorrect_model, trial = diff_trials[1], timeStep = 10.0, stateStep = 0.1, debug = true)\n\n_, prStates_im_ss, probUpCrossing_im_ss, probDownCrossing_im_ss = ADDM.aDDM_get_trial_likelihood(;model = incorrect_model, trial = diff_trials[1], timeStep = 10.0, stateStep = 0.01, debug = true)\n\nlikMax = maximum(vcat(probUpCrossing_cm_ls, probDownCrossing_cm_ls, probUpCrossing_cm_ss, probDownCrossing_cm_ss, probUpCrossing_im_ls, probDownCrossing_im_ls, probUpCrossing_im_ss, probDownCrossing_im_ss))\nlikelihoodLims = (0, likMax);\nprStateLims = (0, 0.05);\n\np1 = state_space_plot(prStates_cm_ls, probUpCrossing_cm_ls, probDownCrossing_cm_ls, 10, 0.1, likelihoodLims, prStateLims);\np2 = state_space_plot(prStates_cm_ss, probUpCrossing_cm_ss, probDownCrossing_cm_ss, 10, 0.01, likelihoodLims, prStateLims);\np3 = state_space_plot(prStates_im_ls, probUpCrossing_im_ls, probDownCrossing_im_ls, 10, 0.1, likelihoodLims, prStateLims);\np4 = state_space_plot(prStates_im_ss, probUpCrossing_im_ss, probDownCrossing_im_ss, 10, 0.01, likelihoodLims, prStateLims);\n\nplot_array = Any[];\npush!(plot_array, p1);\npush!(plot_array, p2);\npush!(plot_array, p3);\npush!(plot_array, p4);\nplot(plot_array...)","category":"page"}]
}
