<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Defining custom models · ADDM.jl</title><meta name="title" content="Defining custom models · ADDM.jl"/><meta property="og:title" content="Defining custom models · ADDM.jl"/><meta property="twitter:title" content="Defining custom models · ADDM.jl"/><meta name="description" content="Documentation for ADDM.jl."/><meta property="og:description" content="Documentation for ADDM.jl."/><meta property="twitter:description" content="Documentation for ADDM.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="ADDM.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">ADDM.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../getting_started/">Getting started with ADDM.jl</a></li><li><a class="tocitem" href="../empirical_data/">Parameter estimation on empirical data</a></li><li class="is-active"><a class="tocitem" href>Defining custom models</a><ul class="internal"><li><a class="tocitem" href="#Load-package"><span>Load package</span></a></li><li><a class="tocitem" href="#Define-simulator"><span>Define simulator</span></a></li><li><a class="tocitem" href="#Define-model-container"><span>Define model container</span></a></li><li><a class="tocitem" href="#Define-likelihood-function"><span>Define likelihood function</span></a></li></ul></li><li><a class="tocitem" href="../model_comparison/">Uncertainty in the best fitting parameters of a single generative process</a></li></ul></li><li><a class="tocitem" href="../../apireference/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Defining custom models</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Defining custom models</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/aDDM-Toolbox/ADDM.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/aDDM-Toolbox/ADDM.jl/blob/main/docs/src/tutorials/custom_model.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Defining-custom-models"><a class="docs-heading-anchor" href="#Defining-custom-models">Defining custom models</a><a id="Defining-custom-models-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-custom-models" title="Permalink"></a></h1><p>Though the packages comes with the standard attentional DDM that allows for multiplicative and additive discounting of unattended items, users might also conceive of other generative processes (within the sequantial sampling to a bound framework) that give rise to observed choices, response times.  </p><p>In this tutorial we lay out the framework for how to incorporate such models within our toolbox to take advantage of Julia&#39;s processing speed.  </p><p>Broadly, this involves defining three parts: </p><ol><li>trial simulator describing how the new parameter changes the data generating process resulting in a choice and response time</li></ol><ul><li>this is then fed into <code>ADDM.simulate_data</code> along with the model object and stimuli to generate choice and response times.</li></ul><ol><li>model object with new parameter</li></ol><ul><li>this is only a container of key-value pairs of parameter names and values used a convenient wrapper to feed into the simulator and likelihood computer.</li></ul><ol><li>trial likelihood calculator computing the probability of the observed choice and response time</li></ol><ul><li>this is then fed into <code>ADDM.grid_search</code> along with the data you want to compute the likelihoods for and the parameter search space.</li></ul><h2 id="Load-package"><a class="docs-heading-anchor" href="#Load-package">Load package</a><a id="Load-package-1"></a><a class="docs-heading-anchor-permalink" href="#Load-package" title="Permalink"></a></h2><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using ADDM</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; using Distributions</code><code class="nohighlight hljs ansi" style="display:block;"></code></pre><h2 id="Define-simulator"><a class="docs-heading-anchor" href="#Define-simulator">Define simulator</a><a id="Define-simulator-1"></a><a class="docs-heading-anchor-permalink" href="#Define-simulator" title="Permalink"></a></h2><p>The built-in model has a <code>decay</code> parameter for a linear decay of the <code>barrier</code>. Let&#39;s build a model with an exponential decay of the barrier such that the barrier at each timestep is defined as <code>barrier(t) = exp(-λt)</code>.</p><p>Based on the <a href="https://github.com/aDDM-Toolbox/ADDM.jl/blob/main/src/simulate_data.jl">built-in trial simulators as defined here</a> the trial simulator would look like the following:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; function my_trial_simulator(;model::ADDM.aDDM, fixationData::ADDM.FixationData,
                               valueLeft::Number, valueRight::Number,
                               timeStep::Number=10.0, numFixDists::Int64=3, cutOff::Number=100000)
       
           fixUnfixValueDiffs = Dict(1 =&gt; valueLeft - valueRight, 2 =&gt; valueRight - valueLeft)
       
           fixItem = Number[]
           fixTime = Number[]
           fixRDV = Number[]
       
           RDV = model.bias
           trialTime = 0
           choice = 0
           tRDV = Number[RDV]
           RT = 0
           uninterruptedLastFixTime = 0
           ndtTimeSteps = Int64(model.nonDecisionTime ÷ timeStep)
       
           # The values of the barriers can change over time.
           # In this case we include an exponential decay
           # Due to the shape of the exponential decay function the starting point for the decay is exp(0) = 1
           barrierUp = exp.(-model.λ .* (0:cutOff-1))
           barrierDown = -exp.(-model.λ .* (0:cutOff-1))
       
           # Sample and iterate over the latency for this trial.
           latency = rand(fixationData.latencies)
           remainingNDT = model.nonDecisionTime - latency
       
           # This will not change anything (i.e. move the RDV) if there is no latency data in the fixations
           for t in 1:Int64(latency ÷ timeStep)
               # Sample the change in RDV from the distribution.
               RDV += rand(Normal(0, model.σ))
               push!(tRDV, RDV)
       
               # If the RDV hit one of the barriers, the trial is over.
               # No barrier decay before decision-related accummulation
               if abs(RDV) &gt;= model.barrier
                   choice = RDV &gt;= 0 ? -1 : 1
                   push!(fixRDV, RDV)
                   push!(fixItem, 0)
                   push!(fixTime, t * timeStep)
                   trialTime += t * timeStep
                   RT = trialTime
                   uninterruptedLastFixTime = latency
                   trial = Trial(choice = choice, RT = RT, valueLeft = valueLeft, valueRight = valueRight)
                   trial.fixItem = fixItem
                   trial.fixTime = fixTime
                   trial.fixRDV = fixRDV
                   trial.uninterruptedLastFixTime = uninterruptedLastFixTime
                   trial.RDV = tRDV
                   return trial
               end
           end
       
           # Add latency to this trial&#39;s data
           push!(fixRDV, RDV)
           push!(fixItem, 0)
           push!(fixTime, latency - (latency % timeStep))
           trialTime += latency - (latency % timeStep)
       
           fixNumber = 1
           prevFixItem = -1
           currFixLocation = 0
           decisionReached = false
       
           # Begin decision related accummulation
           cumTimeStep = 0
           while true
               if currFixLocation == 0
                   # This is an item fixation; sample its location.
                   if prevFixItem == -1
                       # Sample the first item fixation for this trial.
                       currFixLocation = rand(Bernoulli(1 - fixationData.probFixLeftFirst)) + 1
                   elseif prevFixItem in [1, 2]
                       currFixLocation = abs(3 - prevFixItem)
                   end
                   prevFixItem = currFixLocation
       
                   # Sample the duration of this item fixation.
                   valueDiff = fixUnfixValueDiffs[currFixLocation]
                   #[1] is here to make sure it&#39;s not sampling from 1-element Vector but from the array inside it
                   currFixTime = rand(fixationData.fixations[fixNumber][valueDiff][1])
       
       
                   if fixNumber &lt; numFixDists
                       fixNumber += 1
                   end
       
               else
                   # This is a transition.
                    currFixLocation = 0
                   # Sample the duration of this transition. The fixation data used below does not have transition information so ignoring this.
                   # currFixTime = rand(fixationData.transitions)
                   currFixTime = 0
               end
       
               # Iterate over the remaining non-decision time remaining after the latency
               # This can span more than first fixation depending on the first fixation duration
               # That&#39;s why it&#39;s not conditioned over the fixation number
               if remainingNDT &gt; 0
                   for t in 1:Int64(remainingNDT ÷ timeStep)
                       # Sample the change in RDV from the distribution.
                       RDV += rand(Normal(0, model.σ))
                       push!(tRDV, RDV)
       
                       # If the RDV hit one of the barriers, the trial is over.
                       # No barrier decay before decision-related accummulation
                       if abs(RDV) &gt;= model.barrier
                           choice = RDV &gt;= 0 ? -1 : 1
                           push!(fixRDV, RDV)
                           push!(fixItem, currFixLocation)
                           push!(fixTime, t * timeStep)
                           trialTime += t * timeStep
                           RT = trialTime
                           uninterruptedLastFixTime = currFixTime
                           decisionReached = true
                           break
                       end
                   end
               end
       
               # Break out of the while loop if decision reached during NDT
               # The break above only breaks from the NDT for loop
               if decisionReached
                   break
               end
       
               remainingFixTime = max(0, currFixTime - max(0, remainingNDT))
               remainingNDT -= currFixTime
       
               # Iterate over the duration of the current fixation.
               # Does not move RDV if there is no fixation time left due to NDT
               for t in 1:Int64(remainingFixTime ÷ timeStep)
                   # We use a distribution to model changes in RDV
                   # stochastically. The mean of the distribution (the change
                   # most likely to occur) is calculated from the model
                   # parameters and from the values of the two items.
                   if currFixLocation == 0
                       μ = 0
                   elseif currFixLocation == 1
                       μ = model.d * ( (valueLeft + model.η) - (model.θ * valueRight))
                   elseif currFixLocation == 2
                       μ = model.d * ((model.θ * valueLeft) - (valueRight + model.η))
                   end
       
                   # Sample the change in RDV from the distribution.
                   RDV += rand(Normal(μ, model.σ))
                   push!(tRDV, RDV)
       
                   # Increment cumulative timestep to look up the correct barrier value in case there has been a decay
                   # Decay in this case only happens during decision-related accummulation (not before)
                   # Don&#39;t want to use t here because this is reset for each fixation throughout a trial but the barrier is not
                   cumTimeStep += 1
       
                   # If the RDV hit one of the barriers, the trial is over.
                   # Decision related accummulation here so barrier might have decayed
                   if abs(RDV) &gt;= barrierUp[cumTimeStep]
                       choice = RDV &gt;= 0 ? -1 : 1
                       push!(fixRDV, RDV)
                       push!(fixItem, currFixLocation)
                       push!(fixTime, t * timeStep)
                       trialTime += t * timeStep
                       RT = trialTime
                       uninterruptedLastFixTime = currFixTime
                       decisionReached = true
                       break
                   end
               end
       
               # Break out of the while loop if decision reached during NDT
               # The break above only breaks from the curFixTime for loop
               if decisionReached
                   break
               end
       
               # Add fixation to this trial&#39;s data.
               push!(fixRDV, RDV)
               push!(fixItem, currFixLocation)
               push!(fixTime, currFixTime - (currFixTime % timeStep))
               trialTime += currFixTime - (currFixTime % timeStep)
       
           end
       
           trial = ADDM.Trial(choice = choice, RT = RT, valueLeft = valueLeft, valueRight = valueRight)
           trial.fixItem = fixItem
           trial.fixTime = fixTime
           trial.fixRDV = fixRDV
           trial.uninterruptedLastFixTime = uninterruptedLastFixTime
           trial.RDV = tRDV
           return trial
       end</code><code class="nohighlight hljs ansi" style="display:block;">my_trial_simulator (generic function with 1 method)</code></pre><h2 id="Define-model-container"><a class="docs-heading-anchor" href="#Define-model-container">Define model container</a><a id="Define-model-container-1"></a><a class="docs-heading-anchor-permalink" href="#Define-model-container" title="Permalink"></a></h2><p>Now create a model object of class <code>aDDM</code> to store the parameters of our model. There are two ways of doing this. First, we could use the <code>ADDM.define_model</code> function. That would like:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_model = ADDM.define_model(d = 0.007, σ = 0.03, θ = .6, barrier = 1, nonDecisionTime = 100, bias = 0.0)</code><code class="nohighlight hljs ansi" style="display:block;">ADDM.aDDM(Dict{Symbol, Any}(:nonDecisionTime =&gt; 100, :σ =&gt; 0.03, :d =&gt; 0.007, :bias =&gt; 0.0, :barrier =&gt; 1, :decay =&gt; 0, :θ =&gt; 0.6, :η =&gt; 0.0))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_model.λ = .05</code><code class="nohighlight hljs ansi" style="display:block;">0.05</code></pre><p>The <code>ADDM.define_model</code> function is limited to the standard parameter names. So the new parameter <code>λ</code> is added to the model after its creation. Alternatively, we can create an empty model object and add our parameters individually.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_model = ADDM.aDDM()</code><code class="nohighlight hljs ansi" style="display:block;">ADDM.aDDM(Dict{Symbol, Any}())</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_model.d = 0.007</code><code class="nohighlight hljs ansi" style="display:block;">0.007</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_model.σ = 0.03</code><code class="nohighlight hljs ansi" style="display:block;">0.03</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_model.θ = .6</code><code class="nohighlight hljs ansi" style="display:block;">0.6</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_model.η = 0</code><code class="nohighlight hljs ansi" style="display:block;">0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_model.barrier = 1</code><code class="nohighlight hljs ansi" style="display:block;">1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_model.nonDecisionTime = 100</code><code class="nohighlight hljs ansi" style="display:block;">100</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_model.bias = 0.0</code><code class="nohighlight hljs ansi" style="display:block;">0.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_model.λ = .05</code><code class="nohighlight hljs ansi" style="display:block;">0.05</code></pre><h3 id="Simulate-data"><a class="docs-heading-anchor" href="#Simulate-data">Simulate data</a><a id="Simulate-data-1"></a><a class="docs-heading-anchor-permalink" href="#Simulate-data" title="Permalink"></a></h3><h4 id="Define-stimuli-and-fixation-distribution"><a class="docs-heading-anchor" href="#Define-stimuli-and-fixation-distribution">Define stimuli and fixation distribution</a><a id="Define-stimuli-and-fixation-distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Define-stimuli-and-fixation-distribution" title="Permalink"></a></h4><p>We will use sample empirical data from Krajbich et al. (2010) to create sample stimuli and fixation distributions. Importantly, we will <em>not</em> be using the empirical choices and response times but instead simulate our own data given the generative process we defined in our custom model and the parameter values we specify for it (i.e. in this notebook we do not fit this custom model to the empirical data from Krajbich et al.).</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using CSV</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; using DataFrames</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; fn = &quot;../../../data/Krajbich2010_stims.csv&quot;</code><code class="nohighlight hljs ansi" style="display:block;">&quot;../../../data/Krajbich2010_stims.csv&quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; tmp = DataFrame(CSV.File(fn, delim=&quot;,&quot;))</code><code class="nohighlight hljs ansi" style="display:block;"><span class="sgr1">978×2 DataFrame
 Row │ item_right  item_left
     │<span class="sgr90"> Int64       Int64
─────┼───────────────────────
   1 │          2          4
   2 │          2          3
   3 │         10          5
   4 │          6          6
   5 │          7          6
   6 │          2          6
   7 │          3          3
   8 │          5          6
  ⋮  │     ⋮           ⋮
 972 │          4          3
 973 │          3          6
 974 │          3          8
 975 │          7          5
 976 │          5          6
 977 │          4          7
 978 │          5          6
</span><span class="sgr36">             963 rows omitted</span></span></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_stims = (valueLeft = tmp.item_left, valueRight = tmp.item_right)</code><code class="nohighlight hljs ansi" style="display:block;">(valueLeft = [4, 3, 5, 6, 6, 6, 3, 6, 5, 6  …  7, 2, 4, 3, 6, 8, 5, 6, 7, 6], valueRight = [2, 2, 10, 6, 7, 2, 3, 5, 8, 8  …  7, 7, 3, 4, 3, 3, 7, 5, 4, 5])</code></pre><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; data = ADDM.load_data_from_csv(&quot;../../../data/Krajbich2010_behavior.csv&quot;, &quot;../../../data/Krajbich2010_fixations.csv&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">Dict{String, Vector{ADDM.Trial}} with 10 entries:
  &quot;14&quot; =&gt; [Trial(-1, 2234, 2, 0, Number[2, 1], Number[399, 737], #undef, #undef…
  &quot;20&quot; =&gt; [Trial(-1, 1991, 4, 2, Number[1, 2, 1], Number[339, 679, 680], #undef…
  &quot;10&quot; =&gt; [Trial(-1, 3808, 4, 2, Number[1, 2, 1, 2, 1, 2, 1], Number[98, 426, 3…
  &quot;17&quot; =&gt; [Trial(-1, 1191, 0, 0, Number[1, 2], Number[340, 638], #undef, #undef…
  &quot;19&quot; =&gt; [Trial(1, 1449, 7, 5, Number[1, 2, 1], Number[258, 677, 99], #undef, …
  &quot;22&quot; =&gt; [Trial(1, 2882, 6, 2, Number[2, 1, 2, 1, 2], Number[259, 797, 595, 57…
  &quot;16&quot; =&gt; [Trial(1, 1251, 5, 5, Number[1, 2], Number[275, 660], #undef, #undef,…
  &quot;11&quot; =&gt; [Trial(-1, 1672, 5, 2, Number[1, 2, 1, 2], Number[338, 440, 319, 380]…
  &quot;13&quot; =&gt; [Trial(1, 3848, 1, 2, Number[1, 2, 1, 2], Number[1036, 757, 997, 757]…
  &quot;18&quot; =&gt; [Trial(-1, 13456, 2, 0, Number[1, 2, 1, 2, 1, 2, 1], Number[637, 2691…</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; vDiffs = sort(unique(my_stims.valueLeft - my_stims.valueRight))</code><code class="nohighlight hljs ansi" style="display:block;">15-element Vector{Int64}:
 -7
 -6
 -5
 -4
 -3
 -2
 -1
  0
  1
  2
  3
  4
  5
  6
  7</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_fixations = ADDM.process_fixations(data, fixDistType=&quot;fixation&quot;, valueDiffs = vDiffs)</code><code class="nohighlight hljs ansi" style="display:block;">ADDM.FixationData(0.7952069716775599, Number[0, 0, 0, 0, 0, 0, 0, 0, 0, 0  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Number[], Dict{Any, Any}(2 =&gt; Dict{Any, Any}(5 =&gt; Vector{Number}[[616, 498, 481, 637, 957, 657, 180, 1036, 877, 439  …  298, 998, 283, 837, 521, 815, 374, 1456, 599, 478]], -3 =&gt; Vector{Number}[[39, 558, 677, 399, 618, 439, 478, 417, 418, 302  …  679, 638, 298, 878, 796, 717, 598, 538, 1076, 378]], -6 =&gt; Vector{Number}[[881, 700, 462]], 1 =&gt; Vector{Number}[[24, 558, 438, 139, 458, 599, 397, 700, 518, 278  …  777, 697, 1076, 919, 438, 679, 1138, 854, 558, 2610]], 0 =&gt; Vector{Number}[[1156, 458, 937, 558, 519, 538, 538, 457, 519, 717  …  818, 1217, 1554, 798, 518, 677, 557, 676, 1136, 577]], 6 =&gt; Vector{Number}[[856, 795, 559, 295, 278]], -5 =&gt; Vector{Number}[[638, 498, 458, 737, 259, 419, 316, 259, 458, 439  …  135, 1036, 419, 838, 1476, 555, 1515, 796, 857, 438]], -1 =&gt; Vector{Number}[[1116, 618, 558, 1235, 657, 378, 516, 516, 379, 398  …  637, 1694, 637, 638, 537, 405, 416, 358, 218, 1475]], -2 =&gt; Vector{Number}[[19, 220, 559, 100, 20, 679, 515, 319, 418, 398  …  2691, 1177, 478, 698, 539, 358, 757, 458, 537, 916]], 3 =&gt; Vector{Number}[[538, 814, 517, 381, 418, 717, 840, 517, 460, 537  …  462, 443, 517, 695, 1335, 478, 558, 418, 498, 457]]…), 3 =&gt; Dict{Any, Any}(5 =&gt; Vector{Number}[[200, 279, 654, 319, 625, 939]], -3 =&gt; Vector{Number}[[658, 599, 478, 440, 597, 179, 1096, 296, 438, 955  …  1650, 539, 956, 558, 996, 977, 1375, 837, 480, 957]], -6 =&gt; Vector{Number}[[239, 1462, 442, 640, 540]], 1 =&gt; Vector{Number}[[538, 563, 740, 1057, 737, 518, 300, 319, 278, 837  …  518, 559, 1033, 697, 796, 1715, 1892, 498, 500, 575]], 0 =&gt; Vector{Number}[[838, 629, 677, 1016, 519, 579, 402, 281, 219, 738  …  1015, 817, 339, 758, 359, 1613, 1423, 1347, 2352, 681]], 6 =&gt; Vector{Number}[[135, 962, 455, 1653, 497]], -5 =&gt; Vector{Number}[[378, 818, 418, 638, 339, 340, 619, 541, 536, 398, 578, 137, 840, 401, 641, 1276, 557, 955]], -1 =&gt; Vector{Number}[[639, 578, 499, 873, 1632, 2210, 458, 798, 618, 2012  …  1972, 1356, 318, 1775, 898, 778, 2573, 399, 2232, 418]], -2 =&gt; Vector{Number}[[478, 259, 382, 582, 479, 239, 616, 798, 817, 756  …  876, 1812, 1268, 638, 1056, 539, 936, 1394, 1994, 897]], 3 =&gt; Vector{Number}[[558, 795, 576, 601, 1295, 757, 737, 1136, 1315, 319  …  1196, 856, 579, 698, 160, 957, 601, 517, 200, 1057]]…), 1 =&gt; Dict{Any, Any}(5 =&gt; Vector{Number}[[398, 518, 438, 217, 539, 339, 339, 240, 179, 461  …  378, 160, 219, 237, 229, 521, 577, 458, 40, 678]], -3 =&gt; Vector{Number}[[737, 459, 555, 359, 339, 478, 438, 418, 259, 459  …  423, 159, 239, 61, 200, 279, 339, 219, 220, 200]], -6 =&gt; Vector{Number}[[366, 241, 757, 200, 220, 245, 17, 199]], 1 =&gt; Vector{Number}[[119, 638, 657, 199, 119, 418, 419, 259, 319, 597  …  558, 658, 398, 219, 260, 40, 239, 319, 259, 179]], 0 =&gt; Vector{Number}[[239, 398, 518, 59, 99, 207, 299, 379, 358, 318  …  797, 577, 419, 298, 381, 338, 219, 379, 219, 319]], 6 =&gt; Vector{Number}[[225, 511, 943, 475, 244, 279]], -5 =&gt; Vector{Number}[[199, 318, 339, 319, 479, 540, 299, 140, 498, 219  …  219, 599, 637, 339, 198, 259, 237, 299, 286, 325]], -1 =&gt; Vector{Number}[[459, 336, 359, 236, 318, 438, 359, 279, 379, 398  …  359, 299, 399, 279, 318, 358, 319, 420, 273, 239]], -2 =&gt; Vector{Number}[[399, 339, 639, 714, 1015, 598, 477, 438, 399, 319  …  1135, 637, 837, 458, 398, 299, 339, 179, 259, 458]], 3 =&gt; Vector{Number}[[518, 102, 518, 338, 518, 498, 339, 417, 497, 378  …  819, 313, 278, 398, 229, 438, 299, 457, 457, 219]]…)), &quot;fixation&quot;)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # There no second fixation durations for vDiff == 7 so we&#39;ll use the third fixation info for second too.
       my_fixations.fixations[2][7] = my_fixations.fixations[3][7]</code><code class="nohighlight hljs ansi" style="display:block;">1-element Vector{Vector{Number}}:
 [2210, 263, 606, 122, 214]</code></pre><h4 id="Simulate-choice-and-response-times"><a class="docs-heading-anchor" href="#Simulate-choice-and-response-times">Simulate choice and response times</a><a id="Simulate-choice-and-response-times-1"></a><a class="docs-heading-anchor-permalink" href="#Simulate-choice-and-response-times" title="Permalink"></a></h4><p>There are 979 rows in the stims. We&#39;ll add more trials to help recover true parameters.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_args = (timeStep = 10.0, cutOff = 20000, fixationData = my_fixations)</code><code class="nohighlight hljs ansi" style="display:block;">(timeStep = 10.0, cutOff = 20000, fixationData = ADDM.FixationData(0.7952069716775599, Number[0, 0, 0, 0, 0, 0, 0, 0, 0, 0  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Number[], Dict{Any, Any}(2 =&gt; Dict{Any, Any}(5 =&gt; Vector{Number}[[616, 498, 481, 637, 957, 657, 180, 1036, 877, 439  …  298, 998, 283, 837, 521, 815, 374, 1456, 599, 478]], -3 =&gt; Vector{Number}[[39, 558, 677, 399, 618, 439, 478, 417, 418, 302  …  679, 638, 298, 878, 796, 717, 598, 538, 1076, 378]], -6 =&gt; Vector{Number}[[881, 700, 462]], 1 =&gt; Vector{Number}[[24, 558, 438, 139, 458, 599, 397, 700, 518, 278  …  777, 697, 1076, 919, 438, 679, 1138, 854, 558, 2610]], 0 =&gt; Vector{Number}[[1156, 458, 937, 558, 519, 538, 538, 457, 519, 717  …  818, 1217, 1554, 798, 518, 677, 557, 676, 1136, 577]], 6 =&gt; Vector{Number}[[856, 795, 559, 295, 278]], -5 =&gt; Vector{Number}[[638, 498, 458, 737, 259, 419, 316, 259, 458, 439  …  135, 1036, 419, 838, 1476, 555, 1515, 796, 857, 438]], -1 =&gt; Vector{Number}[[1116, 618, 558, 1235, 657, 378, 516, 516, 379, 398  …  637, 1694, 637, 638, 537, 405, 416, 358, 218, 1475]], -2 =&gt; Vector{Number}[[19, 220, 559, 100, 20, 679, 515, 319, 418, 398  …  2691, 1177, 478, 698, 539, 358, 757, 458, 537, 916]], 3 =&gt; Vector{Number}[[538, 814, 517, 381, 418, 717, 840, 517, 460, 537  …  462, 443, 517, 695, 1335, 478, 558, 418, 498, 457]]…), 3 =&gt; Dict{Any, Any}(5 =&gt; Vector{Number}[[200, 279, 654, 319, 625, 939]], -3 =&gt; Vector{Number}[[658, 599, 478, 440, 597, 179, 1096, 296, 438, 955  …  1650, 539, 956, 558, 996, 977, 1375, 837, 480, 957]], -6 =&gt; Vector{Number}[[239, 1462, 442, 640, 540]], 1 =&gt; Vector{Number}[[538, 563, 740, 1057, 737, 518, 300, 319, 278, 837  …  518, 559, 1033, 697, 796, 1715, 1892, 498, 500, 575]], 0 =&gt; Vector{Number}[[838, 629, 677, 1016, 519, 579, 402, 281, 219, 738  …  1015, 817, 339, 758, 359, 1613, 1423, 1347, 2352, 681]], 6 =&gt; Vector{Number}[[135, 962, 455, 1653, 497]], -5 =&gt; Vector{Number}[[378, 818, 418, 638, 339, 340, 619, 541, 536, 398, 578, 137, 840, 401, 641, 1276, 557, 955]], -1 =&gt; Vector{Number}[[639, 578, 499, 873, 1632, 2210, 458, 798, 618, 2012  …  1972, 1356, 318, 1775, 898, 778, 2573, 399, 2232, 418]], -2 =&gt; Vector{Number}[[478, 259, 382, 582, 479, 239, 616, 798, 817, 756  …  876, 1812, 1268, 638, 1056, 539, 936, 1394, 1994, 897]], 3 =&gt; Vector{Number}[[558, 795, 576, 601, 1295, 757, 737, 1136, 1315, 319  …  1196, 856, 579, 698, 160, 957, 601, 517, 200, 1057]]…), 1 =&gt; Dict{Any, Any}(5 =&gt; Vector{Number}[[398, 518, 438, 217, 539, 339, 339, 240, 179, 461  …  378, 160, 219, 237, 229, 521, 577, 458, 40, 678]], -3 =&gt; Vector{Number}[[737, 459, 555, 359, 339, 478, 438, 418, 259, 459  …  423, 159, 239, 61, 200, 279, 339, 219, 220, 200]], -6 =&gt; Vector{Number}[[366, 241, 757, 200, 220, 245, 17, 199]], 1 =&gt; Vector{Number}[[119, 638, 657, 199, 119, 418, 419, 259, 319, 597  …  558, 658, 398, 219, 260, 40, 239, 319, 259, 179]], 0 =&gt; Vector{Number}[[239, 398, 518, 59, 99, 207, 299, 379, 358, 318  …  797, 577, 419, 298, 381, 338, 219, 379, 219, 319]], 6 =&gt; Vector{Number}[[225, 511, 943, 475, 244, 279]], -5 =&gt; Vector{Number}[[199, 318, 339, 319, 479, 540, 299, 140, 498, 219  …  219, 599, 637, 339, 198, 259, 237, 299, 286, 325]], -1 =&gt; Vector{Number}[[459, 336, 359, 236, 318, 438, 359, 279, 379, 398  …  359, 299, 399, 279, 318, 358, 319, 420, 273, 239]], -2 =&gt; Vector{Number}[[399, 339, 639, 714, 1015, 598, 477, 438, 399, 319  …  1135, 637, 837, 458, 398, 299, 339, 179, 259, 458]], 3 =&gt; Vector{Number}[[518, 102, 518, 338, 518, 498, 339, 417, 497, 378  …  819, 313, 278, 398, 229, 438, 299, 457, 457, 219]]…)), &quot;fixation&quot;))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_sim_data = ADDM.simulate_data(my_model, my_stims, my_trial_simulator, my_args)</code><code class="nohighlight hljs ansi" style="display:block;">978-element Vector{ADDM.Trial}:
 ADDM.Trial(-1, 300.0, 4, 2, Number[0, 1, 0, 2], Number[0.0, 190.0, 0.0, 110.0], Number[0.0, 0.35796671571272076, 0.35796671571272076, 0.47050618934112276], 180, Number[0.0, 0.015165158124729218, 0.038945654040733746, 0.06954585103137569, 0.12241927373596559, 0.1175039545502793, 0.10260256573669856, 0.037132796821602365, 0.08578807846164416, 0.14449498408915415  …  0.3525426046160931, 0.3896856603320473, 0.3739200796729834, 0.3491323568487161, 0.38688626082973826, 0.3958771187175625, 0.42155065296398875, 0.3570074349891954, 0.3994406365018818, 0.47050618934112276])
 ADDM.Trial(1, 330.0, 3, 2, Number[0, 2], Number[0.0, 330.0], Number[0.0, -0.23048268069429476], 737, Number[0.0, 0.006777446989133311, -0.023611693637113483, -0.03447567141277003, -0.07388663111454308, -0.08527143811817023, -0.10658041234815185, -0.09252039941140443, -0.09659748182487213, -0.11816729863776838  …  -0.16288605298176212, -0.17398151901015205, -0.1703142819254932, -0.18608596432619653, -0.1970867370185015, -0.15701571747997525, -0.1523017682083379, -0.15954535091123062, -0.20328192086578453, -0.23048268069429476])
 ADDM.Trial(1, 350.0, 5, 10, Number[0, 2, 0, 1], Number[0.0, 180.0, 0.0, 170.0], Number[0.0, -0.174341593809064, -0.174341593809064, -0.3145714488052486], 638, Number[0.0, 0.03878915332800731, 0.056129584911293814, 0.09428868311237133, 0.12415544772557399, 0.10022273505763148, 0.0892223297854805, 0.12002964502721558, 0.1373206230283436, 0.11471195567032033  …  -0.23757126759264288, -0.2730187505471737, -0.28238384115398474, -0.27909732500550327, -0.31806428732802694, -0.3129128470825609, -0.26407081802774457, -0.30117628845697547, -0.2808268741649918, -0.3145714488052486])
 ADDM.Trial(-1, 160.0, 6, 6, Number[0, 1], Number[0.0, 160.0], Number[0.0, 0.4847694980988658], 321, Number[0.0, 0.0020345546306655108, -0.04047626241992574, -0.017024844133813263, -0.020378772964711907, -0.0334889815179573, -0.04763475769167818, -0.06130929707146787, -0.006273596333157758, 0.017558903378348714  …  0.2602523240177304, 0.24551326014061672, 0.28945529552401644, 0.32533968874736596, 0.3812527087396462, 0.3896809803201668, 0.42791364691141365, 0.4828827079456207, 0.4355567377646487, 0.4847694980988658])
 ADDM.Trial(-1, 230.0, 6, 7, Number[0, 1], Number[0.0, 230.0], Number[0.0, 0.37321303656256155], 1612, Number[0.0, 0.03458923621995948, 0.02788321367954392, 0.08016204591483966, 0.13085969710904505, 0.1183086286892545, 0.12930437817831555, 0.14035851102060212, 0.1695250365402313, 0.15884592805114414  …  0.29387113871507586, 0.3003054146116938, 0.2929875963696051, 0.2505169867994811, 0.2506559826892059, 0.27363514963300545, 0.24599939577180202, 0.300081358425633, 0.32437779939611416, 0.37321303656256155])
 ADDM.Trial(-1, 160.0, 6, 2, Number[0, 1], Number[0.0, 160.0], Number[0.0, 0.49621164557517217], 458, Number[0.0, -0.07121297686257752, -0.09418717279710478, -0.05241403777965149, -0.03377616588214159, -0.037928040473578534, -0.0803048964155021, -0.019307816910956142, -0.031183303819210622, -0.010346562945297094  …  0.19123361016080195, 0.2112676090359981, 0.27950827146215595, 0.258281012752917, 0.26428302349091015, 0.28334073068704513, 0.37887963312749506, 0.44077511734773955, 0.4819481436261444, 0.49621164557517217])
 ADDM.Trial(-1, 250.0, 3, 3, Number[0, 1], Number[0.0, 250.0], Number[0.0, 0.3517642634797218], 419, Number[0.0, -0.00873471424675472, 0.018520442064438092, 0.013154638554356266, 0.03071073180418353, 0.04103753024460178, 0.08092842901066641, 0.06472769728513006, 0.10059070768676362, 0.09555894293292536  …  0.218187437695938, 0.19044979240328572, 0.21862187051219592, 0.25681415173437144, 0.24382618101053438, 0.26503594265640046, 0.2783755797835007, 0.28819134255677653, 0.29378866578951096, 0.3517642634797218])
 ADDM.Trial(1, 220.0, 6, 5, Number[0, 2], Number[0.0, 220.0], Number[0.0, -0.35109168319599404], 378, Number[0.0, 0.03729805121947227, 0.00902674355117675, 0.02807374523489845, 0.05903778174962663, 0.04594082604454283, 0.041843833157520424, 0.010208121542488062, 0.022968840719384667, -0.00798494660614853  …  -0.24852781325546627, -0.2606655004429856, -0.30186646622277835, -0.27893108192522154, -0.3096090012573428, -0.2849874785969621, -0.27855172756804747, -0.27713507989799946, -0.3204970248131119, -0.35109168319599404])
 ADDM.Trial(1, 260.0, 5, 8, Number[0, 1, 0, 2], Number[0.0, 170.0, 0.0, 90.0], Number[0.0, -0.08364866106765606, -0.08364866106765606, -0.4728982711413541], 518, Number[0.0, -0.05544066977818445, -0.036131039593710626, -0.05277307444625619, -0.03236822357626817, -0.03239180777790893, -0.08339443266235019, -0.10494240474176364, -0.13592051590344584, -0.12982974036687445  …  -0.08364866106765606, -0.14390633396691996, -0.22200734547861425, -0.2609888162302881, -0.284944728857369, -0.3323312624487559, -0.40083466428024717, -0.42359563523688853, -0.4206146811105876, -0.4728982711413541])
 ADDM.Trial(1, 420.0, 6, 8, Number[0, 1, 0, 2], Number[0.0, 330.0, 0.0, 90.0], Number[0.0, 0.09805417562967006, 0.09805417562967006, -0.22794478198726809], 677, Number[0.0, -0.03478872726942566, -0.055208329567575196, -0.01817911392455694, 0.004285556532727559, 0.019503600359477704, -0.02979085064037083, -0.037851827183565195, -0.0477263608791408, -0.06742615500171761  …  0.09805417562967006, 0.046598988351830094, 0.0692206852294147, 0.034714392624763064, 0.0031479544192373962, -0.03764897679822043, -0.03414032423270805, -0.052362794364378504, -0.15722593003514077, -0.22794478198726809])
 ⋮
 ADDM.Trial(1, 360.0, 2, 7, Number[0, 1, 0, 2], Number[0.0, 330.0, 0.0, 30.0], Number[0.0, -0.21591332278081715, -0.21591332278081715, -0.29733237895496045], 657, Number[0.0, 0.020942468678787417, 0.014128570241285141, 0.034706497217705246, 0.07059438825286979, 0.06580230088413182, 0.030673003720444424, 0.05604585445808448, 0.09436369684150925, 0.10368604961801728  …  -0.29782098085825565, -0.23712260813167216, -0.249407033433361, -0.21334388209073873, -0.1730565096406522, -0.17190801130546132, -0.21591332278081715, -0.2321694516019595, -0.2836846371601732, -0.29733237895496045])
 ADDM.Trial(-1, 150.0, 4, 3, Number[0, 1], Number[0.0, 150.0], Number[0.0, 0.509068084010241], 398, Number[0.0, -0.023562110561465566, -0.01039556440281992, -0.049879511299907746, 0.013624798932292202, 0.030865218219965358, 0.033060515377251694, 0.07787278583650853, 0.11764332228388649, 0.06914083670160892  …  0.17756880050458979, 0.20881058363252286, 0.24641968189559268, 0.24918461565052372, 0.30921192715769674, 0.35583313582373455, 0.37653685226622446, 0.4696291246235582, 0.5084126298843191, 0.509068084010241])
 ADDM.Trial(-1, 590.0, 3, 4, Number[0, 1], Number[0.0, 590.0], Number[0.0, 0.06551774587381709], 737, Number[0.0, -0.02512979400473974, -0.008281022016375546, 0.0058046757638861475, 0.006044208911171461, 0.021008926960135347, 0.011439790366359611, -0.036152059208800866, -0.05920842896697794, -0.04509118307264846  …  -0.044672085426076105, 0.0011324160557274615, 0.02466917908681518, 0.0244427885098563, 0.05848793297405716, 0.03986692267904362, 0.03274093949376623, 0.03235350540970087, 0.026287321463487685, 0.06551774587381709])
 ADDM.Trial(-1, 160.0, 6, 3, Number[0, 1], Number[0.0, 160.0], Number[0.0, 0.47378682080198], 398, Number[0.0, 0.061415947797309474, 0.07325132970264492, 0.1429349479439667, 0.1525200385668631, 0.16045034805960467, 0.22196803385441488, 0.2362135594891774, 0.21881273901982948, 0.23029992283183395  …  0.2933695473220771, 0.3027910505332989, 0.3021477459404186, 0.29603229584271795, 0.3603491927032485, 0.39735382034232636, 0.3819277680267492, 0.40639538234251177, 0.4246364149832841, 0.47378682080198])
 ADDM.Trial(-1, 190.0, 8, 3, Number[0, 1, 0, 2], Number[0.0, 170.0, 0.0, 20.0], Number[0.0, 0.5817014611157012, 0.5817014611157012, 0.6716448567092469], 259, Number[0.0, 0.04156875601878306, 0.08285210504197818, 0.08559087149851066, 0.05948600801910888, 0.011099253855862905, 0.009305621246995846, 0.013022965683185474, 0.01859247470250003, 0.08441762927223033, 0.08605571873346587, 0.1771405234116566, 0.31257159836245485, 0.3832939519831743, 0.4838895356491262, 0.511119195737055, 0.5725640538980824, 0.5817014611157012, 0.6133484994698033, 0.6716448567092469])
 ADDM.Trial(1, 370.0, 5, 7, Number[0, 1, 0, 2], Number[0.0, 320.0, 0.0, 50.0], Number[0.0, -0.08457290619045052, -0.08457290619045052, -0.2744777683729891], 338, Number[0.0, -0.02342899401420399, -0.055720391252519264, -0.009668731663020243, -0.051465293511205004, -0.077016271745496, -0.10685407022540303, -0.1644665830594994, -0.181625670011526, -0.15123240441024943  …  -0.05880615685623741, -0.059846848840071645, -0.07773837868920996, -0.06604535799492153, -0.08457290619045052, -0.1786923250779813, -0.19613635409967922, -0.24816329983023838, -0.2664869814042334, -0.2744777683729891])
 ADDM.Trial(1, 700.0, 6, 5, Number[0, 1, 0, 2], Number[0.0, 290.0, 0.0, 410.0], Number[0.0, 0.24889321320997976, 0.24889321320997976, -0.0732672111148158], 738, Number[0.0, -0.007910718669620277, 0.04925412637319179, 0.03856230867460101, -0.005502654255292554, -0.015796680203251014, -0.07132033706709576, -0.03531138517782511, -0.07159520874382405, -0.08334844989858341  …  -0.04184207803387604, 0.007002140839429842, 0.0019867202748461692, 0.03702942581609426, 0.019391526157655086, 0.006179837100359662, 0.015889610843237884, 0.020853221869295096, -0.01861807165622086, -0.0732672111148158])
 ADDM.Trial(-1, 160.0, 7, 4, Number[0, 1], Number[0.0, 160.0], Number[0.0, 0.5017699999255958], 319, Number[0.0, 0.011323548055604732, 0.005352115781821911, 0.0019329475083129542, -0.010926517791950547, -0.006553113428235128, 0.03882624434271681, 0.08165162371274108, 0.10493076024005944, 0.07230105236082959  …  0.17949613117549315, 0.2059034756035074, 0.2647551870971425, 0.29663087762345824, 0.35366256401390106, 0.39922578124628183, 0.45780946391127636, 0.5123842083367652, 0.4823163283723865, 0.5017699999255958])
 ADDM.Trial(1, 250.0, 6, 5, Number[0, 2], Number[0.0, 250.0], Number[0.0, -0.32157810769304124], 457, Number[0.0, 0.012845950487926769, -0.0450556542786013, -0.015994301070793433, 0.003504006188348615, -0.004315186542192116, 0.034654704172707176, 0.01189822826021546, -0.0017862821558681033, -0.0033830949507013984  …  -0.20515414939108909, -0.22725259141406093, -0.274224598020418, -0.26384237372246216, -0.24775895003554188, -0.22839070196547226, -0.3065825830057362, -0.30713858266164384, -0.2934966540298054, -0.32157810769304124])</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; for i in 1:2
         this_sim_data = ADDM.simulate_data(my_model, my_stims, my_trial_simulator, my_args)
         append!(my_sim_data, this_sim_data)
         i += 1
       end</code><code class="nohighlight hljs ansi" style="display:block;"></code></pre><h2 id="Define-likelihood-function"><a class="docs-heading-anchor" href="#Define-likelihood-function">Define likelihood function</a><a id="Define-likelihood-function-1"></a><a class="docs-heading-anchor-permalink" href="#Define-likelihood-function" title="Permalink"></a></h2><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; function my_likelihood_fn(;model::ADDM.aDDM, trial::ADDM.Trial, timeStep::Number = 10.0,
                                          approxStateStep::Number = 0.1)
       
           # Iterate over the fixations and discount the non-decision time.
           if model.nonDecisionTime &gt; 0
               correctedFixItem = Number[]
               correctedFixTime = Number[]
               remainingNDT = model.nonDecisionTime
               for (fItem, fTime) in zip(trial.fixItem, trial.fixTime) # iterate through each fixation in the trial
                   if remainingNDT &gt; 0
                       push!(correctedFixItem, 0)
                       push!(correctedFixTime, min(remainingNDT, fTime)) # if the fTime is smaller push that otherwise push ndt
                       push!(correctedFixItem, fItem)
                       push!(correctedFixTime, max(fTime - remainingNDT, 0))
                       remainingNDT = remainingNDT - fTime
                   else
                       push!(correctedFixItem, fItem)
                       push!(correctedFixTime, fTime)
                   end
               end
           else
               correctedFixItem = trial.fixItem
               correctedFixTime = trial.fixTime
           end
       
           # Iterate over the fixations and get the number of time steps for this trial.
           numTimeSteps = 0
       
           for fTime in correctedFixTime
               numTimeSteps += Int64(fTime ÷ timeStep)
           end
       
           if numTimeSteps &lt; 1
               throw(RuntimeError(&quot;Trial response time is smaller than time step.&quot;))
           end
           numTimeSteps += 1
       
           # The values of the barriers can change over time.
           barrierUp = exp.(-model.λ .* (0:numTimeSteps-1))
           barrierDown = -exp.(-model.λ .* (0:numTimeSteps-1))
       
           # Obtain correct state step.
           halfNumStateBins = ceil(model.barrier / approxStateStep)
           stateStep = model.barrier / (halfNumStateBins + 0.5)
       
           # The vertical axis is divided into states.
           states = range(-1*(model.barrier) + stateStep / 2, 1*(model.barrier) - stateStep/2, step=stateStep)
       
           # Find the state corresponding to the bias parameter.
           biasState = argmin(abs.(states .- model.bias))
       
           # Initial probability for all states is zero, except the bias state,
           # for which the initial probability is one.
           prStates = zeros(length(states), numTimeSteps)
           prStates[biasState,1] = 1
       
           # The probability of crossing each barrier over the time of the trial.
           probUpCrossing = zeros(numTimeSteps)
           probDownCrossing = zeros(numTimeSteps)
       
           time = 1
       
           # Dictionary of μ values from fItem.
           μDict = Dict{Number, Number}()
           for fItem in 0:2
               if fItem == 1
                   μ = model.d * ((trial.valueLeft + model.η) - (model.θ * trial.valueRight))
               elseif fItem == 2
                   μ = model.d * ((model.θ * trial.valueLeft) - (trial.valueRight + model.η))
               else
                   μ = 0
               end
       
               μDict[fItem] = μ
           end
       
           changeMatrix = states .- reshape(states, 1, :)
           changeUp = (barrierUp .- reshape(states, 1, :))&#39;
           changeDown = (barrierDown .- reshape(states, 1, :) )&#39;
       
           pdfDict = Dict{Number, Any}()
           cdfUpDict = Dict{Number, Any}()
           cdfDownDict = Dict{Number, Any}()
       
           for fItem in 0:2
               normpdf = similar(changeMatrix)
               cdfUp = similar(changeUp[:, time])
               cdfDown = similar(changeDown[:, time])
       
               @. normpdf = pdf(Normal(μDict[fItem], model.σ), changeMatrix)
               @. cdfUp = cdf(Normal(μDict[fItem], model.σ), changeUp[:, time])
               @. cdfDown = cdf(Normal(μDict[fItem], model.σ), changeDown[:, time])
               pdfDict[fItem] = normpdf
               cdfUpDict[fItem] = cdfUp
               cdfDownDict[fItem] = cdfDown
           end
       
           # Iterate over all fixations in this trial.
           for (fItem, fTime) in zip(correctedFixItem, correctedFixTime)
               # We use a normal distribution to model changes in RDV
               # stochastically. The mean of the distribution (the change most
               # likely to occur) is calculated from the model parameters and from
               # the item values.
               μ = μDict[fItem]
               normpdf = pdfDict[fItem]
               cdfUp = cdfUpDict[fItem]
               cdfDown = cdfDownDict[fItem]
       
               # Iterate over the time interval of this fixation.
               for t in 1:Int64(fTime ÷ timeStep)
                   # Update the probability of the states that remain inside the
                   # barriers. The probability of being in state B is the sum,
                   # over all states A, of the probability of being in A at the
                   # previous timestep times the probability of changing from A to
                   # B. We multiply the probability by the stateStep to ensure
                   # that the area under the curves for the probability
                   # distributions probUpCrossing and probDownCrossing add up to 1.
                   prStatesNew = stateStep * (normpdf * prStates[:,time])
                   prStatesNew[(states .&gt;= barrierUp[time]) .| (states .&lt;= barrierDown[time])] .= 0
       
                   # Calculate the probabilities of crossing the up barrier and
                   # the down barrier. This is given by the sum, over all states
                   # A, of the proability of being in A at the previous timestep
                   # times the probability of crossing the barrier if A is the
                   # previous state.
                   tempUpCross = dot(prStates[:,time], 1 .- cdfUp)
                   tempDownCross = dot(prStates[:,time], cdfDown)
       
                   # Renormalize to cope with numerical approximations.
                   sumIn = sum(prStates[:,time])
                   sumCurrent = sum(prStatesNew) + tempUpCross + tempDownCross
                   prStatesNew = prStatesNew * sumIn / sumCurrent
                   tempUpCross = tempUpCross * sumIn / sumCurrent
                   tempDownCross = tempDownCross * sumIn / sumCurrent
       
                   # Update the probabilities of each state and the probabilities of
                   # crossing each barrier at this timestep
                   prStates[:,time+1] = prStatesNew
                   probUpCrossing[time+1] = tempUpCross
                   probDownCrossing[time+1] = tempDownCross
       
                   time += 1
               end
           end
       
           # Compute the likelihood contribution of this trial based on the final
           # choice.
           likelihood = 0
           if trial.choice == -1 # Choice was left.
               if probUpCrossing[end] &gt; 0
                   likelihood = probUpCrossing[end]
               end
           elseif trial.choice == 1 # Choice was right.
               if probDownCrossing[end] &gt; 0
                   likelihood = probDownCrossing[end]
               end
           end
       
           return likelihood
       end</code><code class="nohighlight hljs ansi" style="display:block;">my_likelihood_fn (generic function with 1 method)</code></pre><h3 id="Recover-parameters-for-simulated-data"><a class="docs-heading-anchor" href="#Recover-parameters-for-simulated-data">Recover parameters for simulated data</a><a id="Recover-parameters-for-simulated-data-1"></a><a class="docs-heading-anchor-permalink" href="#Recover-parameters-for-simulated-data" title="Permalink"></a></h3><h4 id="Define-search-grid"><a class="docs-heading-anchor" href="#Define-search-grid">Define search grid</a><a id="Define-search-grid-1"></a><a class="docs-heading-anchor-permalink" href="#Define-search-grid" title="Permalink"></a></h4><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; fn = &quot;../../../data/custom_model_grid.csv&quot;</code><code class="nohighlight hljs ansi" style="display:block;">&quot;../../../data/custom_model_grid.csv&quot;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; tmp = DataFrame(CSV.File(fn, delim=&quot;,&quot;))</code><code class="nohighlight hljs ansi" style="display:block;"><span class="sgr1">81×4 DataFrame
 Row │ d        sigma    theta    lambda
     │<span class="sgr90"> Float64  Float64  Float64  Float64
─────┼────────────────────────────────────
   1 │   0.003     0.01      0.0      0.0
   2 │   0.007     0.01      0.0      0.0
   3 │   0.014     0.01      0.0      0.0
   4 │   0.003     0.03      0.0      0.0
   5 │   0.007     0.03      0.0      0.0
   6 │   0.014     0.03      0.0      0.0
   7 │   0.003     0.07      0.0      0.0
   8 │   0.007     0.07      0.0      0.0
  ⋮  │    ⋮        ⋮        ⋮        ⋮
  75 │   0.014     0.01      0.9      0.1
  76 │   0.003     0.03      0.9      0.1
  77 │   0.007     0.03      0.9      0.1
  78 │   0.014     0.03      0.9      0.1
  79 │   0.003     0.07      0.9      0.1
  80 │   0.007     0.07      0.9      0.1
  81 │   0.014     0.07      0.9      0.1
</span><span class="sgr36">                           66 rows omitted</span></span></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; param_grid = Dict(pairs(NamedTuple.(eachrow(tmp))))</code><code class="nohighlight hljs ansi" style="display:block;">Dict{Int64, NamedTuple{(:d, :sigma, :theta, :lambda), NTuple{4, Float64}}} with 81 entries:
  5  =&gt; (d = 0.007, sigma = 0.03, theta = 0.0, lambda = 0.0)
  56 =&gt; (d = 0.007, sigma = 0.01, theta = 0.0, lambda = 0.1)
  16 =&gt; (d = 0.003, sigma = 0.07, theta = 0.6, lambda = 0.0)
  20 =&gt; (d = 0.007, sigma = 0.01, theta = 0.9, lambda = 0.0)
  35 =&gt; (d = 0.007, sigma = 0.07, theta = 0.0, lambda = 0.05)
  55 =&gt; (d = 0.003, sigma = 0.01, theta = 0.0, lambda = 0.1)
  79 =&gt; (d = 0.003, sigma = 0.07, theta = 0.9, lambda = 0.1)
  60 =&gt; (d = 0.014, sigma = 0.03, theta = 0.0, lambda = 0.1)
  81 =&gt; (d = 0.014, sigma = 0.07, theta = 0.9, lambda = 0.1)
  30 =&gt; (d = 0.014, sigma = 0.01, theta = 0.0, lambda = 0.05)
  19 =&gt; (d = 0.003, sigma = 0.01, theta = 0.9, lambda = 0.0)
  32 =&gt; (d = 0.007, sigma = 0.03, theta = 0.0, lambda = 0.05)
  49 =&gt; (d = 0.003, sigma = 0.03, theta = 0.9, lambda = 0.05)
  6  =&gt; (d = 0.014, sigma = 0.03, theta = 0.0, lambda = 0.0)
  67 =&gt; (d = 0.003, sigma = 0.03, theta = 0.6, lambda = 0.1)
  45 =&gt; (d = 0.014, sigma = 0.07, theta = 0.6, lambda = 0.05)
  44 =&gt; (d = 0.007, sigma = 0.07, theta = 0.6, lambda = 0.05)
  9  =&gt; (d = 0.014, sigma = 0.07, theta = 0.0, lambda = 0.0)
  31 =&gt; (d = 0.003, sigma = 0.03, theta = 0.0, lambda = 0.05)
  ⋮  =&gt; ⋮</code></pre><h4 id="Run-grid-search-on-simulated-data"><a class="docs-heading-anchor" href="#Run-grid-search-on-simulated-data">Run grid search on simulated data</a><a id="Run-grid-search-on-simulated-data-1"></a><a class="docs-heading-anchor-permalink" href="#Run-grid-search-on-simulated-data" title="Permalink"></a></h4><p>Even with smaller state space step size the correct decay is not recovered. Instead, the fast response times are attributed to faster drift rates and larger sigmas.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using LinearAlgebra</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; fixed_params = Dict(:η=&gt;0.0, :barrier=&gt;1, :decay=&gt;0, :nonDecisionTime=&gt;100, :bias=&gt;0.0)</code><code class="nohighlight hljs ansi" style="display:block;">Dict{Symbol, Real} with 5 entries:
  :nonDecisionTime =&gt; 100
  :bias            =&gt; 0.0
  :barrier         =&gt; 1
  :decay           =&gt; 0
  :η               =&gt; 0.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; my_likelihood_args = (timeStep = 10.0, approxStateStep = 0.01)</code><code class="nohighlight hljs ansi" style="display:block;">(timeStep = 10.0, approxStateStep = 0.01)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; best_pars, nll_df = ADDM.grid_search(my_sim_data, my_likelihood_fn, param_grid, fixed_params, likelihood_args = my_likelihood_args)</code><code class="nohighlight hljs ansi" style="display:block;">(Dict{Symbol, Real}(:lambda =&gt; 0.0, :nonDecisionTime =&gt; 100, :bias =&gt; 0.0, :d =&gt; 0.014, :barrier =&gt; 1, :sigma =&gt; 0.07, :theta =&gt; 0.6, :decay =&gt; 0, :η =&gt; 0.0, :nll =&gt; 14505.781162858497…), <span class="sgr1">81×5 DataFrame
 Row │ d        lambda   sigma    theta    nll
     │<span class="sgr90"> Float64  Float64  Float64  Float64  Float64
─────┼────────────────────────────────────────────────────
   1 │   0.007     0.0      0.03      0.0   56094.6
   2 │   0.007     0.1      0.01      0.0       4.3237e5
   3 │   0.003     0.0      0.07      0.6   20006.5
   4 │   0.007     0.0      0.01      0.9       2.90602e5
   5 │   0.007     0.05     0.07      0.0  246727.0
   6 │   0.003     0.1      0.01      0.0       4.3237e5
   7 │   0.003     0.1      0.07      0.9       3.48428e5
   8 │   0.014     0.1      0.03      0.0  432338.0
  ⋮  │    ⋮        ⋮        ⋮        ⋮           ⋮
  75 │   0.007     0.0      0.01      0.0       3.12258e5
  76 │   0.003     0.0      0.01      0.6       3.63268e5
  77 │   0.014     0.0      0.07      0.6   14505.8
  78 │   0.007     0.0      0.07      0.9   17966.4
  79 │   0.014     0.0      0.07      0.9   15788.4
  80 │   0.007     0.1      0.01      0.6       4.3237e5
  81 │   0.014     0.05     0.03      0.6       4.26904e5
</span><span class="sgr36">                                           66 rows omitted)</span></span></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; sort!(nll_df, [:nll])</code><code class="nohighlight hljs ansi" style="display:block;"><span class="sgr1">81×5 DataFrame
 Row │ d        lambda   sigma    theta    nll
     │<span class="sgr90"> Float64  Float64  Float64  Float64  Float64
─────┼──────────────────────────────────────────────────
   1 │   0.014     0.0      0.07      0.6  14505.8
   2 │   0.014     0.0      0.07      0.9  15788.4
   3 │   0.007     0.0      0.07      0.6  17556.9
   4 │   0.007     0.0      0.07      0.9  17966.4
   5 │   0.007     0.0      0.07      0.0  18339.3
   6 │   0.014     0.0      0.07      0.0  18481.9
   7 │   0.003     0.0      0.07      0.6  20006.5
   8 │   0.003     0.0      0.07      0.0  20062.0
  ⋮  │    ⋮        ⋮        ⋮        ⋮          ⋮
  75 │   0.014     0.05     0.01      0.6      4.3237e5
  76 │   0.007     0.1      0.03      0.9      4.3237e5
  77 │   0.014     0.1      0.01      0.6      4.3237e5
  78 │   0.003     0.1      0.03      0.9      4.3237e5
  79 │   0.014     0.05     0.01      0.9      4.3237e5
  80 │   0.007     0.1      0.03      0.0      4.3237e5
  81 │   0.007     0.1      0.01      0.6      4.3237e5
</span><span class="sgr36">                                         66 rows omitted</span></span></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; show(nll_df, allrows = true)</code><code class="nohighlight hljs ansi" style="display:block;">81×5 DataFrame
 Row │ d        lambda   sigma    theta    nll
     │ Float64  Float64  Float64  Float64  Float64
─────┼────────────────────────────────────────────────────
   1 │   0.014     0.0      0.07      0.6   14505.8
   2 │   0.014     0.0      0.07      0.9   15788.4
   3 │   0.007     0.0      0.07      0.6   17556.9
   4 │   0.007     0.0      0.07      0.9   17966.4
   5 │   0.007     0.0      0.07      0.0   18339.3
   6 │   0.014     0.0      0.07      0.0   18481.9
   7 │   0.003     0.0      0.07      0.6   20006.5
   8 │   0.003     0.0      0.07      0.0   20062.0
   9 │   0.003     0.0      0.07      0.9   20130.8
  10 │   0.014     0.0      0.03      0.6   36910.1
  11 │   0.014     0.0      0.03      0.9   42684.3
  12 │   0.007     0.0      0.03      0.6   51050.5
  13 │   0.007     0.0      0.03      0.9   52434.3
  14 │   0.007     0.0      0.03      0.0   56094.6
  15 │   0.014     0.0      0.03      0.0   57710.1
  16 │   0.003     0.0      0.03      0.6   62627.1
  17 │   0.003     0.0      0.03      0.9   62855.3
  18 │   0.003     0.0      0.03      0.0   63599.7
  19 │   0.014     0.0      0.01      0.6       2.18009e5
  20 │   0.014     0.0      0.01      0.9       2.24931e5
  21 │   0.014     0.05     0.07      0.0       2.29618e5
  22 │   0.014     0.05     0.07      0.6       2.4066e5
  23 │   0.014     0.05     0.07      0.9       2.46406e5
  24 │   0.007     0.05     0.07      0.0  246727.0
  25 │   0.014     0.0      0.01      0.0       2.52217e5
  26 │   0.007     0.05     0.07      0.6       2.52684e5
  27 │   0.007     0.05     0.07      0.9       2.54614e5
  28 │   0.003     0.05     0.07      0.0       2.57053e5
  29 │   0.003     0.05     0.07      0.6       2.58263e5
  30 │   0.003     0.05     0.07      0.9       2.59605e5
  31 │   0.007     0.0      0.01      0.9       2.90602e5
  32 │   0.007     0.0      0.01      0.6       3.04853e5
  33 │   0.007     0.0      0.01      0.0       3.12258e5
  34 │   0.014     0.1      0.07      0.0       3.241e5
  35 │   0.014     0.1      0.07      0.6  332833.0
  36 │   0.014     0.1      0.07      0.9       3.3688e5
  37 │   0.007     0.1      0.07      0.0       3.38588e5
  38 │   0.007     0.1      0.07      0.6       3.41848e5
  39 │   0.007     0.1      0.07      0.9       3.4317e5
  40 │   0.003     0.1      0.07      0.0       3.44927e5
  41 │   0.003     0.1      0.07      0.6  347329.0
  42 │   0.003     0.1      0.07      0.9       3.48428e5
  43 │   0.003     0.0      0.01      0.9       3.53791e5
  44 │   0.003     0.0      0.01      0.6       3.63268e5
  45 │   0.003     0.0      0.01      0.0       3.7075e5
  46 │   0.014     0.05     0.03      0.0       4.23825e5
  47 │   0.014     0.05     0.03      0.6       4.26904e5
  48 │   0.014     0.05     0.03      0.9       4.27644e5
  49 │   0.007     0.05     0.03      0.0       4.28093e5
  50 │   0.007     0.05     0.03      0.6       4.29066e5
  51 │   0.007     0.05     0.03      0.9       4.29448e5
  52 │   0.003     0.05     0.03      0.0       4.29812e5
  53 │   0.003     0.05     0.03      0.6       4.30133e5
  54 │   0.003     0.05     0.03      0.9       4.30276e5
  55 │   0.014     0.1      0.03      0.0  432338.0
  56 │   0.007     0.1      0.01      0.0       4.3237e5
  57 │   0.003     0.1      0.01      0.0       4.3237e5
  58 │   0.014     0.05     0.01      0.0       4.3237e5
  59 │   0.003     0.1      0.03      0.6       4.3237e5
  60 │   0.003     0.1      0.01      0.9       4.3237e5
  61 │   0.007     0.1      0.01      0.9       4.3237e5
  62 │   0.003     0.1      0.01      0.6       4.3237e5
  63 │   0.007     0.05     0.01      0.0       4.3237e5
  64 │   0.003     0.05     0.01      0.9       4.3237e5
  65 │   0.014     0.1      0.01      0.0       4.3237e5
  66 │   0.007     0.05     0.01      0.6       4.3237e5
  67 │   0.014     0.1      0.03      0.9       4.3237e5
  68 │   0.003     0.1      0.03      0.0       4.3237e5
  69 │   0.003     0.05     0.01      0.0       4.3237e5
  70 │   0.003     0.05     0.01      0.6       4.3237e5
  71 │   0.007     0.05     0.01      0.9       4.3237e5
  72 │   0.007     0.1      0.03      0.6       4.3237e5
  73 │   0.014     0.1      0.03      0.6       4.3237e5
  74 │   0.014     0.1      0.01      0.9       4.3237e5
  75 │   0.014     0.05     0.01      0.6       4.3237e5
  76 │   0.007     0.1      0.03      0.9       4.3237e5
  77 │   0.014     0.1      0.01      0.6       4.3237e5
  78 │   0.003     0.1      0.03      0.9       4.3237e5
  79 │   0.014     0.05     0.01      0.9       4.3237e5
  80 │   0.007     0.1      0.03      0.0       4.3237e5
  81 │   0.007     0.1      0.01      0.6       4.3237e5</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../empirical_data/">« Parameter estimation on empirical data</a><a class="docs-footer-nextpage" href="../model_comparison/">Uncertainty in the best fitting parameters of a single generative process »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Thursday 1 February 2024 23:30">Thursday 1 February 2024</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
